2023-01-09 17:55:13,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:55:13,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:55:13,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:55:13,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:55:15,393:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-09 17:55:38,571:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 17:56:02,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:56:02,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:56:02,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:56:02,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 17:56:02,996:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-09 17:56:05,844:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 18:00:25,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:00:25,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:00:25,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:00:25,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:00:26,412:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-09 18:00:29,244:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 18:01:08,005:INFO:PyCaret RegressionExperiment
2023-01-09 18:01:08,005:INFO:Logging name: reg-default-name
2023-01-09 18:01:08,006:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-09 18:01:08,006:INFO:version 3.0.0.rc7
2023-01-09 18:01:08,006:INFO:Initializing setup()
2023-01-09 18:01:08,006:INFO:self.USI: 8563
2023-01-09 18:01:08,006:INFO:self._variable_keys: {'X', 'n_jobs_param', 'fold_generator', 'gpu_param', 'idx', 'html_param', 'X_train', 'gpu_n_jobs_param', '_available_plots', 'exp_name_log', 'data', 'exp_id', 'memory', '_ml_usecase', 'y_train', 'fold_groups_param', 'y_test', 'transform_target_param', 'target_param', 'USI', 'pipeline', 'y', 'X_test', 'seed', 'fold_shuffle_param', 'logging_param', 'log_plots_param'}
2023-01-09 18:01:08,006:INFO:Checking environment
2023-01-09 18:01:08,006:INFO:python_version: 3.10.5
2023-01-09 18:01:08,006:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-01-09 18:01:08,006:INFO:machine: AMD64
2023-01-09 18:01:08,023:INFO:platform: Windows-10-10.0.19045-SP0
2023-01-09 18:01:08,024:INFO:Memory: svmem(total=8494747648, available=1727631360, percent=79.7, used=6767116288, free=1727631360)
2023-01-09 18:01:08,024:INFO:Physical Core: 4
2023-01-09 18:01:08,024:INFO:Logical Core: 8
2023-01-09 18:01:08,024:INFO:Checking libraries
2023-01-09 18:01:08,024:INFO:System:
2023-01-09 18:01:08,024:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-01-09 18:01:08,024:INFO:executable: C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\Scripts\python.exe
2023-01-09 18:01:08,024:INFO:   machine: Windows-10-10.0.19045-SP0
2023-01-09 18:01:08,024:INFO:PyCaret required dependencies:
2023-01-09 18:01:08,024:INFO:                 pip: 22.3.1
2023-01-09 18:01:08,024:INFO:          setuptools: 58.1.0
2023-01-09 18:01:08,024:INFO:             pycaret: 3.0.0rc7
2023-01-09 18:01:08,024:INFO:             IPython: 8.8.0
2023-01-09 18:01:08,024:INFO:          ipywidgets: 8.0.4
2023-01-09 18:01:08,024:INFO:                tqdm: 4.64.1
2023-01-09 18:01:08,024:INFO:               numpy: 1.23.5
2023-01-09 18:01:08,024:INFO:              pandas: 1.5.2
2023-01-09 18:01:08,024:INFO:              jinja2: 3.1.2
2023-01-09 18:01:08,024:INFO:               scipy: 1.9.3
2023-01-09 18:01:08,024:INFO:              joblib: 1.2.0
2023-01-09 18:01:08,024:INFO:             sklearn: 1.1.3
2023-01-09 18:01:08,024:INFO:                pyod: 1.0.7
2023-01-09 18:01:08,024:INFO:            imblearn: 0.10.1
2023-01-09 18:01:08,024:INFO:   category_encoders: 2.5.1.post0
2023-01-09 18:01:08,024:INFO:            lightgbm: 3.3.4
2023-01-09 18:01:08,024:INFO:               numba: 0.56.4
2023-01-09 18:01:08,024:INFO:            requests: 2.28.1
2023-01-09 18:01:08,024:INFO:          matplotlib: 3.6.2
2023-01-09 18:01:08,024:INFO:          scikitplot: 0.3.7
2023-01-09 18:01:08,024:INFO:         yellowbrick: 1.5
2023-01-09 18:01:08,024:INFO:              plotly: 5.11.0
2023-01-09 18:01:08,024:INFO:             kaleido: 0.2.1
2023-01-09 18:01:08,024:INFO:         statsmodels: 0.13.5
2023-01-09 18:01:08,024:INFO:              sktime: 0.15.0
2023-01-09 18:01:08,024:INFO:               tbats: 1.1.2
2023-01-09 18:01:08,024:INFO:            pmdarima: 2.0.2
2023-01-09 18:01:08,024:INFO:              psutil: 5.9.4
2023-01-09 18:01:08,024:INFO:PyCaret optional dependencies:
2023-01-09 18:01:08,049:INFO:                shap: Not installed
2023-01-09 18:01:08,049:INFO:           interpret: Not installed
2023-01-09 18:01:08,049:INFO:                umap: Not installed
2023-01-09 18:01:08,049:INFO:    pandas_profiling: 3.6.2
2023-01-09 18:01:08,049:INFO:  explainerdashboard: Not installed
2023-01-09 18:01:08,049:INFO:             autoviz: Not installed
2023-01-09 18:01:08,049:INFO:           fairlearn: Not installed
2023-01-09 18:01:08,049:INFO:             xgboost: Not installed
2023-01-09 18:01:08,049:INFO:            catboost: Not installed
2023-01-09 18:01:08,049:INFO:              kmodes: Not installed
2023-01-09 18:01:08,049:INFO:             mlxtend: Not installed
2023-01-09 18:01:08,049:INFO:       statsforecast: Not installed
2023-01-09 18:01:08,049:INFO:        tune_sklearn: Not installed
2023-01-09 18:01:08,049:INFO:                 ray: Not installed
2023-01-09 18:01:08,049:INFO:            hyperopt: Not installed
2023-01-09 18:01:08,049:INFO:              optuna: Not installed
2023-01-09 18:01:08,049:INFO:               skopt: Not installed
2023-01-09 18:01:08,049:INFO:              mlflow: Not installed
2023-01-09 18:01:08,049:INFO:              gradio: Not installed
2023-01-09 18:01:08,049:INFO:             fastapi: Not installed
2023-01-09 18:01:08,049:INFO:             uvicorn: Not installed
2023-01-09 18:01:08,049:INFO:              m2cgen: Not installed
2023-01-09 18:01:08,049:INFO:           evidently: Not installed
2023-01-09 18:01:08,049:INFO:                nltk: Not installed
2023-01-09 18:01:08,049:INFO:            pyLDAvis: Not installed
2023-01-09 18:01:08,049:INFO:              gensim: Not installed
2023-01-09 18:01:08,049:INFO:               spacy: Not installed
2023-01-09 18:01:08,049:INFO:           wordcloud: Not installed
2023-01-09 18:01:08,049:INFO:            textblob: Not installed
2023-01-09 18:01:08,049:INFO:               fugue: Not installed
2023-01-09 18:01:08,049:INFO:           streamlit: 1.16.0
2023-01-09 18:01:08,049:INFO:             prophet: Not installed
2023-01-09 18:01:08,049:INFO:None
2023-01-09 18:01:08,049:INFO:Set up data.
2023-01-09 18:01:08,068:INFO:Set up train/test split.
2023-01-09 18:01:08,068:INFO:Set up index.
2023-01-09 18:01:08,068:INFO:Set up folding strategy.
2023-01-09 18:01:08,068:INFO:Assigning column types.
2023-01-09 18:01:08,068:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-09 18:01:08,068:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,081:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,261:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,272:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,381:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-09 18:01:08,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,512:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,637:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-09 18:01:08,647:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:08,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:08,882:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-09 18:01:08,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-09 18:01:09,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:01:09,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,391:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-09 18:01:09,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:09,633:INFO:Preparing preprocessing pipeline...
2023-01-09 18:01:09,641:INFO:Set up simple imputation.
2023-01-09 18:01:09,694:INFO:Finished creating preprocessing pipeline.
2023-01-09 18:01:09,694:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-09 18:01:09,694:INFO:Creating final display dataframe.
2023-01-09 18:01:09,949:INFO:Setup _display_container:                     Description             Value
0                    Session id              1705
1                        Target       MedHouseVal
2                   Target type        Regression
3           Original data shape        (15480, 9)
4        Transformed data shape        (15480, 9)
5   Transformed train set shape        (10836, 9)
6    Transformed test set shape         (4644, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8563
2023-01-09 18:01:10,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:10,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:10,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:10,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:01:10,197:INFO:setup() successfully completed in 2.2s...............
2023-01-09 18:01:10,269:INFO:Initializing compare_models()
2023-01-09 18:01:10,269:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-09 18:01:10,269:INFO:Checking exceptions
2023-01-09 18:01:10,272:INFO:Preparing display monitor
2023-01-09 18:01:10,283:INFO:Initializing Linear Regression
2023-01-09 18:01:10,284:INFO:Total runtime is 1.7098585764567058e-05 minutes
2023-01-09 18:01:10,284:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:10,284:INFO:Initializing create_model()
2023-01-09 18:01:10,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:10,285:INFO:Checking exceptions
2023-01-09 18:01:10,285:INFO:Importing libraries
2023-01-09 18:01:10,285:INFO:Copying training dataset
2023-01-09 18:01:10,313:INFO:Defining folds
2023-01-09 18:01:10,313:INFO:Declaring metric variables
2023-01-09 18:01:10,314:INFO:Importing untrained model
2023-01-09 18:01:10,315:INFO:Linear Regression Imported successfully
2023-01-09 18:01:10,316:INFO:Starting cross validation
2023-01-09 18:01:10,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:15,081:INFO:Calculating mean and std
2023-01-09 18:01:15,081:INFO:Creating metrics dataframe
2023-01-09 18:01:15,094:INFO:Uploading results into container
2023-01-09 18:01:15,095:INFO:Uploading model into container now
2023-01-09 18:01:15,096:INFO:_master_model_container: 1
2023-01-09 18:01:15,096:INFO:_display_container: 2
2023-01-09 18:01:15,096:INFO:LinearRegression(n_jobs=-1)
2023-01-09 18:01:15,096:INFO:create_model() successfully completed......................................
2023-01-09 18:01:15,189:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:15,189:INFO:Creating metrics dataframe
2023-01-09 18:01:15,194:INFO:Initializing Lasso Regression
2023-01-09 18:01:15,194:INFO:Total runtime is 0.08184710343678793 minutes
2023-01-09 18:01:15,194:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:15,195:INFO:Initializing create_model()
2023-01-09 18:01:15,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:15,195:INFO:Checking exceptions
2023-01-09 18:01:15,195:INFO:Importing libraries
2023-01-09 18:01:15,195:INFO:Copying training dataset
2023-01-09 18:01:15,199:INFO:Defining folds
2023-01-09 18:01:15,199:INFO:Declaring metric variables
2023-01-09 18:01:15,199:INFO:Importing untrained model
2023-01-09 18:01:15,200:INFO:Lasso Regression Imported successfully
2023-01-09 18:01:15,200:INFO:Starting cross validation
2023-01-09 18:01:15,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:15,329:INFO:Calculating mean and std
2023-01-09 18:01:15,329:INFO:Creating metrics dataframe
2023-01-09 18:01:15,343:INFO:Uploading results into container
2023-01-09 18:01:15,344:INFO:Uploading model into container now
2023-01-09 18:01:15,344:INFO:_master_model_container: 2
2023-01-09 18:01:15,344:INFO:_display_container: 2
2023-01-09 18:01:15,345:INFO:Lasso(random_state=1705)
2023-01-09 18:01:15,345:INFO:create_model() successfully completed......................................
2023-01-09 18:01:15,432:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:15,432:INFO:Creating metrics dataframe
2023-01-09 18:01:15,432:INFO:Initializing Ridge Regression
2023-01-09 18:01:15,432:INFO:Total runtime is 0.08582125107447307 minutes
2023-01-09 18:01:15,432:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:15,432:INFO:Initializing create_model()
2023-01-09 18:01:15,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:15,432:INFO:Checking exceptions
2023-01-09 18:01:15,432:INFO:Importing libraries
2023-01-09 18:01:15,432:INFO:Copying training dataset
2023-01-09 18:01:15,432:INFO:Defining folds
2023-01-09 18:01:15,432:INFO:Declaring metric variables
2023-01-09 18:01:15,448:INFO:Importing untrained model
2023-01-09 18:01:15,448:INFO:Ridge Regression Imported successfully
2023-01-09 18:01:15,449:INFO:Starting cross validation
2023-01-09 18:01:15,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:15,500:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.88723e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,503:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.8957e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,515:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.90165e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,517:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.91472e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,533:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.95867e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,534:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=2.0807e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,561:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.95835e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,573:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.9376e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,581:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.92337e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,583:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.55692e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:01:15,583:INFO:Calculating mean and std
2023-01-09 18:01:15,583:INFO:Creating metrics dataframe
2023-01-09 18:01:15,602:INFO:Uploading results into container
2023-01-09 18:01:15,603:INFO:Uploading model into container now
2023-01-09 18:01:15,604:INFO:_master_model_container: 3
2023-01-09 18:01:15,604:INFO:_display_container: 2
2023-01-09 18:01:15,604:INFO:Ridge(random_state=1705)
2023-01-09 18:01:15,604:INFO:create_model() successfully completed......................................
2023-01-09 18:01:15,683:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:15,683:INFO:Creating metrics dataframe
2023-01-09 18:01:15,699:INFO:Initializing Elastic Net
2023-01-09 18:01:15,699:INFO:Total runtime is 0.09026170174280802 minutes
2023-01-09 18:01:15,699:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:15,699:INFO:Initializing create_model()
2023-01-09 18:01:15,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:15,699:INFO:Checking exceptions
2023-01-09 18:01:15,699:INFO:Importing libraries
2023-01-09 18:01:15,699:INFO:Copying training dataset
2023-01-09 18:01:15,699:INFO:Defining folds
2023-01-09 18:01:15,699:INFO:Declaring metric variables
2023-01-09 18:01:15,699:INFO:Importing untrained model
2023-01-09 18:01:15,699:INFO:Elastic Net Imported successfully
2023-01-09 18:01:15,707:INFO:Starting cross validation
2023-01-09 18:01:15,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:15,833:INFO:Calculating mean and std
2023-01-09 18:01:15,833:INFO:Creating metrics dataframe
2023-01-09 18:01:15,844:INFO:Uploading results into container
2023-01-09 18:01:15,845:INFO:Uploading model into container now
2023-01-09 18:01:15,845:INFO:_master_model_container: 4
2023-01-09 18:01:15,845:INFO:_display_container: 2
2023-01-09 18:01:15,846:INFO:ElasticNet(random_state=1705)
2023-01-09 18:01:15,846:INFO:create_model() successfully completed......................................
2023-01-09 18:01:15,932:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:15,932:INFO:Creating metrics dataframe
2023-01-09 18:01:15,932:INFO:Initializing Least Angle Regression
2023-01-09 18:01:15,932:INFO:Total runtime is 0.09414244095484416 minutes
2023-01-09 18:01:15,932:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:15,932:INFO:Initializing create_model()
2023-01-09 18:01:15,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:15,932:INFO:Checking exceptions
2023-01-09 18:01:15,932:INFO:Importing libraries
2023-01-09 18:01:15,932:INFO:Copying training dataset
2023-01-09 18:01:15,932:INFO:Defining folds
2023-01-09 18:01:15,932:INFO:Declaring metric variables
2023-01-09 18:01:15,947:INFO:Importing untrained model
2023-01-09 18:01:15,948:INFO:Least Angle Regression Imported successfully
2023-01-09 18:01:15,949:INFO:Starting cross validation
2023-01-09 18:01:15,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:15,998:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:15,999:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,013:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,017:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,033:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,033:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,049:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,049:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,064:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,068:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,084:INFO:Calculating mean and std
2023-01-09 18:01:16,084:INFO:Creating metrics dataframe
2023-01-09 18:01:16,084:INFO:Uploading results into container
2023-01-09 18:01:16,084:INFO:Uploading model into container now
2023-01-09 18:01:16,084:INFO:_master_model_container: 5
2023-01-09 18:01:16,084:INFO:_display_container: 2
2023-01-09 18:01:16,092:INFO:Lars(random_state=1705)
2023-01-09 18:01:16,092:INFO:create_model() successfully completed......................................
2023-01-09 18:01:16,184:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:16,184:INFO:Creating metrics dataframe
2023-01-09 18:01:16,189:INFO:Initializing Lasso Least Angle Regression
2023-01-09 18:01:16,189:INFO:Total runtime is 0.09843564430872599 minutes
2023-01-09 18:01:16,190:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:16,190:INFO:Initializing create_model()
2023-01-09 18:01:16,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:16,190:INFO:Checking exceptions
2023-01-09 18:01:16,190:INFO:Importing libraries
2023-01-09 18:01:16,190:INFO:Copying training dataset
2023-01-09 18:01:16,194:INFO:Defining folds
2023-01-09 18:01:16,194:INFO:Declaring metric variables
2023-01-09 18:01:16,194:INFO:Importing untrained model
2023-01-09 18:01:16,194:INFO:Lasso Least Angle Regression Imported successfully
2023-01-09 18:01:16,195:INFO:Starting cross validation
2023-01-09 18:01:16,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:16,232:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,247:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,247:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,263:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,281:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,287:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,300:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,300:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,300:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,316:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:01:16,331:INFO:Calculating mean and std
2023-01-09 18:01:16,331:INFO:Creating metrics dataframe
2023-01-09 18:01:16,331:INFO:Uploading results into container
2023-01-09 18:01:16,331:INFO:Uploading model into container now
2023-01-09 18:01:16,340:INFO:_master_model_container: 6
2023-01-09 18:01:16,340:INFO:_display_container: 2
2023-01-09 18:01:16,340:INFO:LassoLars(random_state=1705)
2023-01-09 18:01:16,340:INFO:create_model() successfully completed......................................
2023-01-09 18:01:16,432:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:16,432:INFO:Creating metrics dataframe
2023-01-09 18:01:16,432:INFO:Initializing Orthogonal Matching Pursuit
2023-01-09 18:01:16,432:INFO:Total runtime is 0.10248032410939534 minutes
2023-01-09 18:01:16,432:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:16,432:INFO:Initializing create_model()
2023-01-09 18:01:16,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:16,432:INFO:Checking exceptions
2023-01-09 18:01:16,432:INFO:Importing libraries
2023-01-09 18:01:16,432:INFO:Copying training dataset
2023-01-09 18:01:16,432:INFO:Defining folds
2023-01-09 18:01:16,432:INFO:Declaring metric variables
2023-01-09 18:01:16,432:INFO:Importing untrained model
2023-01-09 18:01:16,432:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-09 18:01:16,432:INFO:Starting cross validation
2023-01-09 18:01:16,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:16,484:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,493:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,500:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,515:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,515:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,515:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,531:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,553:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,559:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,573:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:01:16,583:INFO:Calculating mean and std
2023-01-09 18:01:16,583:INFO:Creating metrics dataframe
2023-01-09 18:01:16,583:INFO:Uploading results into container
2023-01-09 18:01:16,583:INFO:Uploading model into container now
2023-01-09 18:01:16,591:INFO:_master_model_container: 7
2023-01-09 18:01:16,591:INFO:_display_container: 2
2023-01-09 18:01:16,591:INFO:OrthogonalMatchingPursuit()
2023-01-09 18:01:16,591:INFO:create_model() successfully completed......................................
2023-01-09 18:01:16,669:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:16,669:INFO:Creating metrics dataframe
2023-01-09 18:01:16,685:INFO:Initializing Bayesian Ridge
2023-01-09 18:01:16,685:INFO:Total runtime is 0.1067010482152303 minutes
2023-01-09 18:01:16,685:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:16,685:INFO:Initializing create_model()
2023-01-09 18:01:16,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:16,685:INFO:Checking exceptions
2023-01-09 18:01:16,685:INFO:Importing libraries
2023-01-09 18:01:16,685:INFO:Copying training dataset
2023-01-09 18:01:16,685:INFO:Defining folds
2023-01-09 18:01:16,685:INFO:Declaring metric variables
2023-01-09 18:01:16,685:INFO:Importing untrained model
2023-01-09 18:01:16,685:INFO:Bayesian Ridge Imported successfully
2023-01-09 18:01:16,685:INFO:Starting cross validation
2023-01-09 18:01:16,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:16,832:INFO:Calculating mean and std
2023-01-09 18:01:16,832:INFO:Creating metrics dataframe
2023-01-09 18:01:16,832:INFO:Uploading results into container
2023-01-09 18:01:16,848:INFO:Uploading model into container now
2023-01-09 18:01:16,848:INFO:_master_model_container: 8
2023-01-09 18:01:16,848:INFO:_display_container: 2
2023-01-09 18:01:16,848:INFO:BayesianRidge()
2023-01-09 18:01:16,848:INFO:create_model() successfully completed......................................
2023-01-09 18:01:16,934:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:16,934:INFO:Creating metrics dataframe
2023-01-09 18:01:16,934:INFO:Initializing Passive Aggressive Regressor
2023-01-09 18:01:16,934:INFO:Total runtime is 0.11085340976715087 minutes
2023-01-09 18:01:16,950:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:16,950:INFO:Initializing create_model()
2023-01-09 18:01:16,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:16,950:INFO:Checking exceptions
2023-01-09 18:01:16,950:INFO:Importing libraries
2023-01-09 18:01:16,951:INFO:Copying training dataset
2023-01-09 18:01:16,951:INFO:Defining folds
2023-01-09 18:01:16,951:INFO:Declaring metric variables
2023-01-09 18:01:16,951:INFO:Importing untrained model
2023-01-09 18:01:16,951:INFO:Passive Aggressive Regressor Imported successfully
2023-01-09 18:01:16,951:INFO:Starting cross validation
2023-01-09 18:01:16,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:17,155:INFO:Calculating mean and std
2023-01-09 18:01:17,155:INFO:Creating metrics dataframe
2023-01-09 18:01:17,159:INFO:Uploading results into container
2023-01-09 18:01:17,160:INFO:Uploading model into container now
2023-01-09 18:01:17,160:INFO:_master_model_container: 9
2023-01-09 18:01:17,160:INFO:_display_container: 2
2023-01-09 18:01:17,161:INFO:PassiveAggressiveRegressor(random_state=1705)
2023-01-09 18:01:17,161:INFO:create_model() successfully completed......................................
2023-01-09 18:01:17,262:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:17,262:INFO:Creating metrics dataframe
2023-01-09 18:01:17,267:INFO:Initializing Huber Regressor
2023-01-09 18:01:17,267:INFO:Total runtime is 0.11640172799428303 minutes
2023-01-09 18:01:17,267:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:17,267:INFO:Initializing create_model()
2023-01-09 18:01:17,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:17,267:INFO:Checking exceptions
2023-01-09 18:01:17,267:INFO:Importing libraries
2023-01-09 18:01:17,267:INFO:Copying training dataset
2023-01-09 18:01:17,271:INFO:Defining folds
2023-01-09 18:01:17,271:INFO:Declaring metric variables
2023-01-09 18:01:17,271:INFO:Importing untrained model
2023-01-09 18:01:17,271:INFO:Huber Regressor Imported successfully
2023-01-09 18:01:17,271:INFO:Starting cross validation
2023-01-09 18:01:17,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:17,905:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:17,936:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:17,997:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,007:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,019:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,058:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,078:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,107:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,225:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,240:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:01:18,261:INFO:Calculating mean and std
2023-01-09 18:01:18,261:INFO:Creating metrics dataframe
2023-01-09 18:01:18,261:INFO:Uploading results into container
2023-01-09 18:01:18,261:INFO:Uploading model into container now
2023-01-09 18:01:18,261:INFO:_master_model_container: 10
2023-01-09 18:01:18,261:INFO:_display_container: 2
2023-01-09 18:01:18,268:INFO:HuberRegressor()
2023-01-09 18:01:18,268:INFO:create_model() successfully completed......................................
2023-01-09 18:01:18,362:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:18,362:INFO:Creating metrics dataframe
2023-01-09 18:01:18,368:INFO:Initializing K Neighbors Regressor
2023-01-09 18:01:18,368:INFO:Total runtime is 0.13474561770757038 minutes
2023-01-09 18:01:18,368:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:18,368:INFO:Initializing create_model()
2023-01-09 18:01:18,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:18,369:INFO:Checking exceptions
2023-01-09 18:01:18,369:INFO:Importing libraries
2023-01-09 18:01:18,369:INFO:Copying training dataset
2023-01-09 18:01:18,372:INFO:Defining folds
2023-01-09 18:01:18,372:INFO:Declaring metric variables
2023-01-09 18:01:18,373:INFO:Importing untrained model
2023-01-09 18:01:18,373:INFO:K Neighbors Regressor Imported successfully
2023-01-09 18:01:18,374:INFO:Starting cross validation
2023-01-09 18:01:18,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:18,577:INFO:Calculating mean and std
2023-01-09 18:01:18,578:INFO:Creating metrics dataframe
2023-01-09 18:01:18,581:INFO:Uploading results into container
2023-01-09 18:01:18,582:INFO:Uploading model into container now
2023-01-09 18:01:18,583:INFO:_master_model_container: 11
2023-01-09 18:01:18,583:INFO:_display_container: 2
2023-01-09 18:01:18,583:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-09 18:01:18,583:INFO:create_model() successfully completed......................................
2023-01-09 18:01:18,667:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:18,667:INFO:Creating metrics dataframe
2023-01-09 18:01:18,667:INFO:Initializing Decision Tree Regressor
2023-01-09 18:01:18,667:INFO:Total runtime is 0.1397252321243286 minutes
2023-01-09 18:01:18,667:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:18,667:INFO:Initializing create_model()
2023-01-09 18:01:18,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:18,667:INFO:Checking exceptions
2023-01-09 18:01:18,667:INFO:Importing libraries
2023-01-09 18:01:18,667:INFO:Copying training dataset
2023-01-09 18:01:18,682:INFO:Defining folds
2023-01-09 18:01:18,682:INFO:Declaring metric variables
2023-01-09 18:01:18,682:INFO:Importing untrained model
2023-01-09 18:01:18,682:INFO:Decision Tree Regressor Imported successfully
2023-01-09 18:01:18,682:INFO:Starting cross validation
2023-01-09 18:01:18,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:19,069:INFO:Calculating mean and std
2023-01-09 18:01:19,069:INFO:Creating metrics dataframe
2023-01-09 18:01:19,069:INFO:Uploading results into container
2023-01-09 18:01:19,069:INFO:Uploading model into container now
2023-01-09 18:01:19,076:INFO:_master_model_container: 12
2023-01-09 18:01:19,076:INFO:_display_container: 2
2023-01-09 18:01:19,076:INFO:DecisionTreeRegressor(random_state=1705)
2023-01-09 18:01:19,076:INFO:create_model() successfully completed......................................
2023-01-09 18:01:19,185:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:19,185:INFO:Creating metrics dataframe
2023-01-09 18:01:19,185:INFO:Initializing Random Forest Regressor
2023-01-09 18:01:19,185:INFO:Total runtime is 0.1483604907989502 minutes
2023-01-09 18:01:19,185:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:19,185:INFO:Initializing create_model()
2023-01-09 18:01:19,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:19,185:INFO:Checking exceptions
2023-01-09 18:01:19,185:INFO:Importing libraries
2023-01-09 18:01:19,185:INFO:Copying training dataset
2023-01-09 18:01:19,185:INFO:Defining folds
2023-01-09 18:01:19,185:INFO:Declaring metric variables
2023-01-09 18:01:19,185:INFO:Importing untrained model
2023-01-09 18:01:19,185:INFO:Random Forest Regressor Imported successfully
2023-01-09 18:01:19,185:INFO:Starting cross validation
2023-01-09 18:01:19,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:33,285:INFO:Calculating mean and std
2023-01-09 18:01:33,285:INFO:Creating metrics dataframe
2023-01-09 18:01:33,295:INFO:Uploading results into container
2023-01-09 18:01:33,296:INFO:Uploading model into container now
2023-01-09 18:01:33,297:INFO:_master_model_container: 13
2023-01-09 18:01:33,297:INFO:_display_container: 2
2023-01-09 18:01:33,297:INFO:RandomForestRegressor(n_jobs=-1, random_state=1705)
2023-01-09 18:01:33,298:INFO:create_model() successfully completed......................................
2023-01-09 18:01:33,407:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:33,407:INFO:Creating metrics dataframe
2023-01-09 18:01:33,417:INFO:Initializing Extra Trees Regressor
2023-01-09 18:01:33,417:INFO:Total runtime is 0.3855715155601501 minutes
2023-01-09 18:01:33,417:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:33,417:INFO:Initializing create_model()
2023-01-09 18:01:33,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:33,417:INFO:Checking exceptions
2023-01-09 18:01:33,417:INFO:Importing libraries
2023-01-09 18:01:33,417:INFO:Copying training dataset
2023-01-09 18:01:33,417:INFO:Defining folds
2023-01-09 18:01:33,417:INFO:Declaring metric variables
2023-01-09 18:01:33,417:INFO:Importing untrained model
2023-01-09 18:01:33,425:INFO:Extra Trees Regressor Imported successfully
2023-01-09 18:01:33,425:INFO:Starting cross validation
2023-01-09 18:01:33,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:41,302:INFO:Calculating mean and std
2023-01-09 18:01:41,303:INFO:Creating metrics dataframe
2023-01-09 18:01:41,311:INFO:Uploading results into container
2023-01-09 18:01:41,313:INFO:Uploading model into container now
2023-01-09 18:01:41,314:INFO:_master_model_container: 14
2023-01-09 18:01:41,314:INFO:_display_container: 2
2023-01-09 18:01:41,315:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1705)
2023-01-09 18:01:41,315:INFO:create_model() successfully completed......................................
2023-01-09 18:01:41,457:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:41,457:INFO:Creating metrics dataframe
2023-01-09 18:01:41,457:INFO:Initializing AdaBoost Regressor
2023-01-09 18:01:41,457:INFO:Total runtime is 0.5195574601491292 minutes
2023-01-09 18:01:41,457:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:41,457:INFO:Initializing create_model()
2023-01-09 18:01:41,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:41,457:INFO:Checking exceptions
2023-01-09 18:01:41,457:INFO:Importing libraries
2023-01-09 18:01:41,457:INFO:Copying training dataset
2023-01-09 18:01:41,472:INFO:Defining folds
2023-01-09 18:01:41,472:INFO:Declaring metric variables
2023-01-09 18:01:41,472:INFO:Importing untrained model
2023-01-09 18:01:41,472:INFO:AdaBoost Regressor Imported successfully
2023-01-09 18:01:41,478:INFO:Starting cross validation
2023-01-09 18:01:41,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:43,080:INFO:Calculating mean and std
2023-01-09 18:01:43,080:INFO:Creating metrics dataframe
2023-01-09 18:01:43,085:INFO:Uploading results into container
2023-01-09 18:01:43,086:INFO:Uploading model into container now
2023-01-09 18:01:43,087:INFO:_master_model_container: 15
2023-01-09 18:01:43,087:INFO:_display_container: 2
2023-01-09 18:01:43,087:INFO:AdaBoostRegressor(random_state=1705)
2023-01-09 18:01:43,087:INFO:create_model() successfully completed......................................
2023-01-09 18:01:43,180:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:43,180:INFO:Creating metrics dataframe
2023-01-09 18:01:43,180:INFO:Initializing Gradient Boosting Regressor
2023-01-09 18:01:43,180:INFO:Total runtime is 0.5482859134674072 minutes
2023-01-09 18:01:43,180:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:43,180:INFO:Initializing create_model()
2023-01-09 18:01:43,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:43,180:INFO:Checking exceptions
2023-01-09 18:01:43,180:INFO:Importing libraries
2023-01-09 18:01:43,180:INFO:Copying training dataset
2023-01-09 18:01:43,188:INFO:Defining folds
2023-01-09 18:01:43,191:INFO:Declaring metric variables
2023-01-09 18:01:43,191:INFO:Importing untrained model
2023-01-09 18:01:43,191:INFO:Gradient Boosting Regressor Imported successfully
2023-01-09 18:01:43,192:INFO:Starting cross validation
2023-01-09 18:01:43,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:48,749:INFO:Calculating mean and std
2023-01-09 18:01:48,749:INFO:Creating metrics dataframe
2023-01-09 18:01:48,759:INFO:Uploading results into container
2023-01-09 18:01:48,760:INFO:Uploading model into container now
2023-01-09 18:01:48,760:INFO:_master_model_container: 16
2023-01-09 18:01:48,761:INFO:_display_container: 2
2023-01-09 18:01:48,761:INFO:GradientBoostingRegressor(random_state=1705)
2023-01-09 18:01:48,761:INFO:create_model() successfully completed......................................
2023-01-09 18:01:48,841:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:48,841:INFO:Creating metrics dataframe
2023-01-09 18:01:48,857:INFO:Initializing Light Gradient Boosting Machine
2023-01-09 18:01:48,857:INFO:Total runtime is 0.6428924679756164 minutes
2023-01-09 18:01:48,857:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:48,857:INFO:Initializing create_model()
2023-01-09 18:01:48,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:48,857:INFO:Checking exceptions
2023-01-09 18:01:48,857:INFO:Importing libraries
2023-01-09 18:01:48,857:INFO:Copying training dataset
2023-01-09 18:01:48,857:INFO:Defining folds
2023-01-09 18:01:48,857:INFO:Declaring metric variables
2023-01-09 18:01:48,857:INFO:Importing untrained model
2023-01-09 18:01:48,857:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:01:48,864:INFO:Starting cross validation
2023-01-09 18:01:48,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:49,507:INFO:Calculating mean and std
2023-01-09 18:01:49,509:INFO:Creating metrics dataframe
2023-01-09 18:01:49,514:INFO:Uploading results into container
2023-01-09 18:01:49,515:INFO:Uploading model into container now
2023-01-09 18:01:49,516:INFO:_master_model_container: 17
2023-01-09 18:01:49,516:INFO:_display_container: 2
2023-01-09 18:01:49,517:INFO:LGBMRegressor(random_state=1705)
2023-01-09 18:01:49,517:INFO:create_model() successfully completed......................................
2023-01-09 18:01:49,610:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:49,610:INFO:Creating metrics dataframe
2023-01-09 18:01:49,620:INFO:Initializing Dummy Regressor
2023-01-09 18:01:49,620:INFO:Total runtime is 0.6556137561798095 minutes
2023-01-09 18:01:49,620:INFO:SubProcess create_model() called ==================================
2023-01-09 18:01:49,620:INFO:Initializing create_model()
2023-01-09 18:01:49,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F89BCE57B0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:49,620:INFO:Checking exceptions
2023-01-09 18:01:49,620:INFO:Importing libraries
2023-01-09 18:01:49,620:INFO:Copying training dataset
2023-01-09 18:01:49,620:INFO:Defining folds
2023-01-09 18:01:49,620:INFO:Declaring metric variables
2023-01-09 18:01:49,628:INFO:Importing untrained model
2023-01-09 18:01:49,628:INFO:Dummy Regressor Imported successfully
2023-01-09 18:01:49,629:INFO:Starting cross validation
2023-01-09 18:01:49,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:01:49,772:INFO:Calculating mean and std
2023-01-09 18:01:49,773:INFO:Creating metrics dataframe
2023-01-09 18:01:49,777:INFO:Uploading results into container
2023-01-09 18:01:49,778:INFO:Uploading model into container now
2023-01-09 18:01:49,778:INFO:_master_model_container: 18
2023-01-09 18:01:49,779:INFO:_display_container: 2
2023-01-09 18:01:49,779:INFO:DummyRegressor()
2023-01-09 18:01:49,779:INFO:create_model() successfully completed......................................
2023-01-09 18:01:49,873:INFO:SubProcess create_model() end ==================================
2023-01-09 18:01:49,873:INFO:Creating metrics dataframe
2023-01-09 18:01:49,883:INFO:Initializing create_model()
2023-01-09 18:01:49,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F89CBB5DB0>, estimator=LGBMRegressor(random_state=1705), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:01:49,883:INFO:Checking exceptions
2023-01-09 18:01:49,884:INFO:Importing libraries
2023-01-09 18:01:49,884:INFO:Copying training dataset
2023-01-09 18:01:49,889:INFO:Defining folds
2023-01-09 18:01:49,889:INFO:Declaring metric variables
2023-01-09 18:01:49,890:INFO:Importing untrained model
2023-01-09 18:01:49,890:INFO:Declaring custom model
2023-01-09 18:01:49,891:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:01:49,892:INFO:Cross validation set to False
2023-01-09 18:01:49,892:INFO:Fitting Model
2023-01-09 18:01:50,022:INFO:LGBMRegressor(random_state=1705)
2023-01-09 18:01:50,022:INFO:create_model() successfully completed......................................
2023-01-09 18:01:50,205:INFO:_master_model_container: 18
2023-01-09 18:01:50,205:INFO:_display_container: 2
2023-01-09 18:01:50,206:INFO:LGBMRegressor(random_state=1705)
2023-01-09 18:01:50,206:INFO:compare_models() successfully completed......................................
2023-01-09 18:01:50,216:INFO:Initializing save_model()
2023-01-09 18:01:50,217:INFO:save_model(model=LGBMRegressor(random_state=1705), model_name=best_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-09 18:01:50,217:INFO:Adding model into prep_pipe
2023-01-09 18:01:50,234:INFO:best_model.pkl saved in current working directory
2023-01-09 18:01:50,246:INFO:Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', LGBMRegressor(random_state=1705))])
2023-01-09 18:01:50,246:INFO:save_model() successfully completed......................................
2023-01-09 18:02:53,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:02:53,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:02:53,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:02:53,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-09 18:02:53,824:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-09 18:02:56,655:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 18:03:57,472:INFO:PyCaret RegressionExperiment
2023-01-09 18:03:57,472:INFO:Logging name: reg-default-name
2023-01-09 18:03:57,473:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-09 18:03:57,473:INFO:version 3.0.0.rc7
2023-01-09 18:03:57,473:INFO:Initializing setup()
2023-01-09 18:03:57,473:INFO:self.USI: b1a4
2023-01-09 18:03:57,473:INFO:self._variable_keys: {'exp_id', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'idx', 'X_test', 'seed', 'gpu_n_jobs_param', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'y', 'target_param', '_available_plots', 'html_param', 'memory', 'data', 'exp_name_log', 'fold_generator', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'logging_param', 'transform_target_param'}
2023-01-09 18:03:57,473:INFO:Checking environment
2023-01-09 18:03:57,473:INFO:python_version: 3.10.5
2023-01-09 18:03:57,473:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-01-09 18:03:57,474:INFO:machine: AMD64
2023-01-09 18:03:57,491:INFO:platform: Windows-10-10.0.19045-SP0
2023-01-09 18:03:57,495:INFO:Memory: svmem(total=8494747648, available=2713714688, percent=68.1, used=5781032960, free=2713714688)
2023-01-09 18:03:57,495:INFO:Physical Core: 4
2023-01-09 18:03:57,496:INFO:Logical Core: 8
2023-01-09 18:03:57,496:INFO:Checking libraries
2023-01-09 18:03:57,496:INFO:System:
2023-01-09 18:03:57,496:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-01-09 18:03:57,496:INFO:executable: C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\Scripts\python.exe
2023-01-09 18:03:57,496:INFO:   machine: Windows-10-10.0.19045-SP0
2023-01-09 18:03:57,496:INFO:PyCaret required dependencies:
2023-01-09 18:03:57,496:INFO:                 pip: 22.3.1
2023-01-09 18:03:57,496:INFO:          setuptools: 58.1.0
2023-01-09 18:03:57,496:INFO:             pycaret: 3.0.0rc7
2023-01-09 18:03:57,496:INFO:             IPython: 8.8.0
2023-01-09 18:03:57,496:INFO:          ipywidgets: 8.0.4
2023-01-09 18:03:57,496:INFO:                tqdm: 4.64.1
2023-01-09 18:03:57,497:INFO:               numpy: 1.23.5
2023-01-09 18:03:57,497:INFO:              pandas: 1.5.2
2023-01-09 18:03:57,497:INFO:              jinja2: 3.1.2
2023-01-09 18:03:57,497:INFO:               scipy: 1.9.3
2023-01-09 18:03:57,497:INFO:              joblib: 1.2.0
2023-01-09 18:03:57,497:INFO:             sklearn: 1.1.3
2023-01-09 18:03:57,497:INFO:                pyod: 1.0.7
2023-01-09 18:03:57,497:INFO:            imblearn: 0.10.1
2023-01-09 18:03:57,497:INFO:   category_encoders: 2.5.1.post0
2023-01-09 18:03:57,497:INFO:            lightgbm: 3.3.4
2023-01-09 18:03:57,497:INFO:               numba: 0.56.4
2023-01-09 18:03:57,497:INFO:            requests: 2.28.1
2023-01-09 18:03:57,497:INFO:          matplotlib: 3.6.2
2023-01-09 18:03:57,497:INFO:          scikitplot: 0.3.7
2023-01-09 18:03:57,497:INFO:         yellowbrick: 1.5
2023-01-09 18:03:57,497:INFO:              plotly: 5.11.0
2023-01-09 18:03:57,497:INFO:             kaleido: 0.2.1
2023-01-09 18:03:57,498:INFO:         statsmodels: 0.13.5
2023-01-09 18:03:57,498:INFO:              sktime: 0.15.0
2023-01-09 18:03:57,498:INFO:               tbats: 1.1.2
2023-01-09 18:03:57,498:INFO:            pmdarima: 2.0.2
2023-01-09 18:03:57,498:INFO:              psutil: 5.9.4
2023-01-09 18:03:57,498:INFO:PyCaret optional dependencies:
2023-01-09 18:03:57,512:INFO:                shap: Not installed
2023-01-09 18:03:57,512:INFO:           interpret: Not installed
2023-01-09 18:03:57,512:INFO:                umap: Not installed
2023-01-09 18:03:57,512:INFO:    pandas_profiling: 3.6.2
2023-01-09 18:03:57,512:INFO:  explainerdashboard: Not installed
2023-01-09 18:03:57,512:INFO:             autoviz: Not installed
2023-01-09 18:03:57,512:INFO:           fairlearn: Not installed
2023-01-09 18:03:57,512:INFO:             xgboost: Not installed
2023-01-09 18:03:57,512:INFO:            catboost: Not installed
2023-01-09 18:03:57,512:INFO:              kmodes: Not installed
2023-01-09 18:03:57,512:INFO:             mlxtend: Not installed
2023-01-09 18:03:57,512:INFO:       statsforecast: Not installed
2023-01-09 18:03:57,512:INFO:        tune_sklearn: Not installed
2023-01-09 18:03:57,512:INFO:                 ray: Not installed
2023-01-09 18:03:57,512:INFO:            hyperopt: Not installed
2023-01-09 18:03:57,512:INFO:              optuna: Not installed
2023-01-09 18:03:57,512:INFO:               skopt: Not installed
2023-01-09 18:03:57,512:INFO:              mlflow: Not installed
2023-01-09 18:03:57,512:INFO:              gradio: Not installed
2023-01-09 18:03:57,512:INFO:             fastapi: Not installed
2023-01-09 18:03:57,512:INFO:             uvicorn: Not installed
2023-01-09 18:03:57,512:INFO:              m2cgen: Not installed
2023-01-09 18:03:57,512:INFO:           evidently: Not installed
2023-01-09 18:03:57,512:INFO:                nltk: Not installed
2023-01-09 18:03:57,512:INFO:            pyLDAvis: Not installed
2023-01-09 18:03:57,512:INFO:              gensim: Not installed
2023-01-09 18:03:57,512:INFO:               spacy: Not installed
2023-01-09 18:03:57,512:INFO:           wordcloud: Not installed
2023-01-09 18:03:57,512:INFO:            textblob: Not installed
2023-01-09 18:03:57,512:INFO:               fugue: Not installed
2023-01-09 18:03:57,527:INFO:           streamlit: 1.16.0
2023-01-09 18:03:57,527:INFO:             prophet: Not installed
2023-01-09 18:03:57,527:INFO:None
2023-01-09 18:03:57,527:INFO:Set up data.
2023-01-09 18:03:57,532:INFO:Set up train/test split.
2023-01-09 18:03:57,532:INFO:Set up index.
2023-01-09 18:03:57,532:INFO:Set up folding strategy.
2023-01-09 18:03:57,532:INFO:Assigning column types.
2023-01-09 18:03:57,545:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-09 18:03:57,545:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,545:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,694:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,821:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-09 18:03:57,827:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,832:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:57,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:03:57,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,078:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-09 18:03:58,078:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,217:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,333:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-09 18:03:58,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-09 18:03:58,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:03:58,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,848:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-09 18:03:58,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:58,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,100:INFO:Preparing preprocessing pipeline...
2023-01-09 18:03:59,101:INFO:Set up simple imputation.
2023-01-09 18:03:59,156:INFO:Finished creating preprocessing pipeline.
2023-01-09 18:03:59,161:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude', 'MedHouseVal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-09 18:03:59,161:INFO:Creating final display dataframe.
2023-01-09 18:03:59,404:INFO:Setup _display_container:                     Description             Value
0                    Session id              2540
1                        Target            MedInc
2                   Target type        Regression
3           Original data shape        (15480, 9)
4        Transformed data shape        (15480, 9)
5   Transformed train set shape        (10836, 9)
6    Transformed test set shape         (4644, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b1a4
2023-01-09 18:03:59,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:03:59,678:INFO:setup() successfully completed in 2.21s...............
2023-01-09 18:03:59,684:INFO:Initializing compare_models()
2023-01-09 18:03:59,684:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-09 18:03:59,685:INFO:Checking exceptions
2023-01-09 18:03:59,687:INFO:Preparing display monitor
2023-01-09 18:03:59,692:INFO:Initializing Linear Regression
2023-01-09 18:03:59,693:INFO:Total runtime is 1.6065438588460288e-05 minutes
2023-01-09 18:03:59,694:INFO:SubProcess create_model() called ==================================
2023-01-09 18:03:59,695:INFO:Initializing create_model()
2023-01-09 18:03:59,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:03:59,695:INFO:Checking exceptions
2023-01-09 18:03:59,695:INFO:Importing libraries
2023-01-09 18:03:59,695:INFO:Copying training dataset
2023-01-09 18:03:59,699:INFO:Defining folds
2023-01-09 18:03:59,699:INFO:Declaring metric variables
2023-01-09 18:03:59,699:INFO:Importing untrained model
2023-01-09 18:03:59,700:INFO:Linear Regression Imported successfully
2023-01-09 18:03:59,700:INFO:Starting cross validation
2023-01-09 18:03:59,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:04,616:INFO:Calculating mean and std
2023-01-09 18:04:04,617:INFO:Creating metrics dataframe
2023-01-09 18:04:04,621:INFO:Uploading results into container
2023-01-09 18:04:04,621:INFO:Uploading model into container now
2023-01-09 18:04:04,622:INFO:_master_model_container: 1
2023-01-09 18:04:04,622:INFO:_display_container: 2
2023-01-09 18:04:04,623:INFO:LinearRegression(n_jobs=-1)
2023-01-09 18:04:04,623:INFO:create_model() successfully completed......................................
2023-01-09 18:04:04,718:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:04,718:INFO:Creating metrics dataframe
2023-01-09 18:04:04,723:INFO:Initializing Lasso Regression
2023-01-09 18:04:04,724:INFO:Total runtime is 0.08385865688323975 minutes
2023-01-09 18:04:04,724:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:04,724:INFO:Initializing create_model()
2023-01-09 18:04:04,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:04,724:INFO:Checking exceptions
2023-01-09 18:04:04,724:INFO:Importing libraries
2023-01-09 18:04:04,724:INFO:Copying training dataset
2023-01-09 18:04:04,728:INFO:Defining folds
2023-01-09 18:04:04,729:INFO:Declaring metric variables
2023-01-09 18:04:04,729:INFO:Importing untrained model
2023-01-09 18:04:04,729:INFO:Lasso Regression Imported successfully
2023-01-09 18:04:04,730:INFO:Starting cross validation
2023-01-09 18:04:04,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:04,872:INFO:Calculating mean and std
2023-01-09 18:04:04,873:INFO:Creating metrics dataframe
2023-01-09 18:04:04,876:INFO:Uploading results into container
2023-01-09 18:04:04,877:INFO:Uploading model into container now
2023-01-09 18:04:04,878:INFO:_master_model_container: 2
2023-01-09 18:04:04,879:INFO:_display_container: 2
2023-01-09 18:04:04,879:INFO:Lasso(random_state=2540)
2023-01-09 18:04:04,880:INFO:create_model() successfully completed......................................
2023-01-09 18:04:04,973:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:04,973:INFO:Creating metrics dataframe
2023-01-09 18:04:04,978:INFO:Initializing Ridge Regression
2023-01-09 18:04:04,978:INFO:Total runtime is 0.08810137510299683 minutes
2023-01-09 18:04:04,979:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:04,979:INFO:Initializing create_model()
2023-01-09 18:04:04,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:04,979:INFO:Checking exceptions
2023-01-09 18:04:04,979:INFO:Importing libraries
2023-01-09 18:04:04,979:INFO:Copying training dataset
2023-01-09 18:04:04,983:INFO:Defining folds
2023-01-09 18:04:04,983:INFO:Declaring metric variables
2023-01-09 18:04:04,983:INFO:Importing untrained model
2023-01-09 18:04:04,984:INFO:Ridge Regression Imported successfully
2023-01-09 18:04:04,984:INFO:Starting cross validation
2023-01-09 18:04:04,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:05,029:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.50446e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,029:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.44234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,053:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.42678e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,059:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.4806e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,071:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.49751e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,078:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.60171e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,092:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=2.92059e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,095:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.50778e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,111:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.55883e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,120:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=3.61823e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:05,131:INFO:Calculating mean and std
2023-01-09 18:04:05,132:INFO:Creating metrics dataframe
2023-01-09 18:04:05,135:INFO:Uploading results into container
2023-01-09 18:04:05,136:INFO:Uploading model into container now
2023-01-09 18:04:05,137:INFO:_master_model_container: 3
2023-01-09 18:04:05,137:INFO:_display_container: 2
2023-01-09 18:04:05,137:INFO:Ridge(random_state=2540)
2023-01-09 18:04:05,137:INFO:create_model() successfully completed......................................
2023-01-09 18:04:05,230:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:05,230:INFO:Creating metrics dataframe
2023-01-09 18:04:05,235:INFO:Initializing Elastic Net
2023-01-09 18:04:05,235:INFO:Total runtime is 0.09237480163574219 minutes
2023-01-09 18:04:05,236:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:05,236:INFO:Initializing create_model()
2023-01-09 18:04:05,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:05,236:INFO:Checking exceptions
2023-01-09 18:04:05,236:INFO:Importing libraries
2023-01-09 18:04:05,236:INFO:Copying training dataset
2023-01-09 18:04:05,240:INFO:Defining folds
2023-01-09 18:04:05,240:INFO:Declaring metric variables
2023-01-09 18:04:05,240:INFO:Importing untrained model
2023-01-09 18:04:05,241:INFO:Elastic Net Imported successfully
2023-01-09 18:04:05,241:INFO:Starting cross validation
2023-01-09 18:04:05,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:05,377:INFO:Calculating mean and std
2023-01-09 18:04:05,378:INFO:Creating metrics dataframe
2023-01-09 18:04:05,382:INFO:Uploading results into container
2023-01-09 18:04:05,383:INFO:Uploading model into container now
2023-01-09 18:04:05,384:INFO:_master_model_container: 4
2023-01-09 18:04:05,384:INFO:_display_container: 2
2023-01-09 18:04:05,384:INFO:ElasticNet(random_state=2540)
2023-01-09 18:04:05,384:INFO:create_model() successfully completed......................................
2023-01-09 18:04:05,481:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:05,481:INFO:Creating metrics dataframe
2023-01-09 18:04:05,487:INFO:Initializing Least Angle Regression
2023-01-09 18:04:05,487:INFO:Total runtime is 0.09658311605453491 minutes
2023-01-09 18:04:05,487:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:05,487:INFO:Initializing create_model()
2023-01-09 18:04:05,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:05,488:INFO:Checking exceptions
2023-01-09 18:04:05,488:INFO:Importing libraries
2023-01-09 18:04:05,488:INFO:Copying training dataset
2023-01-09 18:04:05,492:INFO:Defining folds
2023-01-09 18:04:05,492:INFO:Declaring metric variables
2023-01-09 18:04:05,492:INFO:Importing untrained model
2023-01-09 18:04:05,493:INFO:Least Angle Regression Imported successfully
2023-01-09 18:04:05,493:INFO:Starting cross validation
2023-01-09 18:04:05,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:05,539:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,550:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,564:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,565:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,582:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,595:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,598:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,615:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,631:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,631:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:05,647:INFO:Calculating mean and std
2023-01-09 18:04:05,647:INFO:Creating metrics dataframe
2023-01-09 18:04:05,659:INFO:Uploading results into container
2023-01-09 18:04:05,660:INFO:Uploading model into container now
2023-01-09 18:04:05,660:INFO:_master_model_container: 5
2023-01-09 18:04:05,661:INFO:_display_container: 2
2023-01-09 18:04:05,661:INFO:Lars(random_state=2540)
2023-01-09 18:04:05,661:INFO:create_model() successfully completed......................................
2023-01-09 18:04:05,744:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:05,744:INFO:Creating metrics dataframe
2023-01-09 18:04:05,761:INFO:Initializing Lasso Least Angle Regression
2023-01-09 18:04:05,761:INFO:Total runtime is 0.10114448070526123 minutes
2023-01-09 18:04:05,761:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:05,761:INFO:Initializing create_model()
2023-01-09 18:04:05,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:05,761:INFO:Checking exceptions
2023-01-09 18:04:05,762:INFO:Importing libraries
2023-01-09 18:04:05,762:INFO:Copying training dataset
2023-01-09 18:04:05,765:INFO:Defining folds
2023-01-09 18:04:05,766:INFO:Declaring metric variables
2023-01-09 18:04:05,766:INFO:Importing untrained model
2023-01-09 18:04:05,766:INFO:Lasso Least Angle Regression Imported successfully
2023-01-09 18:04:05,767:INFO:Starting cross validation
2023-01-09 18:04:05,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:05,813:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,823:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,831:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,842:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,858:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,864:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,875:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,888:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,898:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,906:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:05,914:INFO:Calculating mean and std
2023-01-09 18:04:05,914:INFO:Creating metrics dataframe
2023-01-09 18:04:05,922:INFO:Uploading results into container
2023-01-09 18:04:05,923:INFO:Uploading model into container now
2023-01-09 18:04:05,923:INFO:_master_model_container: 6
2023-01-09 18:04:05,923:INFO:_display_container: 2
2023-01-09 18:04:05,924:INFO:LassoLars(random_state=2540)
2023-01-09 18:04:05,924:INFO:create_model() successfully completed......................................
2023-01-09 18:04:06,032:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:06,032:INFO:Creating metrics dataframe
2023-01-09 18:04:06,032:INFO:Initializing Orthogonal Matching Pursuit
2023-01-09 18:04:06,032:INFO:Total runtime is 0.10565316677093506 minutes
2023-01-09 18:04:06,032:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:06,032:INFO:Initializing create_model()
2023-01-09 18:04:06,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:06,032:INFO:Checking exceptions
2023-01-09 18:04:06,032:INFO:Importing libraries
2023-01-09 18:04:06,032:INFO:Copying training dataset
2023-01-09 18:04:06,032:INFO:Defining folds
2023-01-09 18:04:06,032:INFO:Declaring metric variables
2023-01-09 18:04:06,032:INFO:Importing untrained model
2023-01-09 18:04:06,044:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-09 18:04:06,045:INFO:Starting cross validation
2023-01-09 18:04:06,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:06,091:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,104:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,111:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,117:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,132:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,149:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,149:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,167:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,180:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,182:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:06,198:INFO:Calculating mean and std
2023-01-09 18:04:06,198:INFO:Creating metrics dataframe
2023-01-09 18:04:06,210:INFO:Uploading results into container
2023-01-09 18:04:06,211:INFO:Uploading model into container now
2023-01-09 18:04:06,211:INFO:_master_model_container: 7
2023-01-09 18:04:06,211:INFO:_display_container: 2
2023-01-09 18:04:06,212:INFO:OrthogonalMatchingPursuit()
2023-01-09 18:04:06,212:INFO:create_model() successfully completed......................................
2023-01-09 18:04:06,312:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:06,312:INFO:Creating metrics dataframe
2023-01-09 18:04:06,318:INFO:Initializing Bayesian Ridge
2023-01-09 18:04:06,318:INFO:Total runtime is 0.11042269468307495 minutes
2023-01-09 18:04:06,318:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:06,318:INFO:Initializing create_model()
2023-01-09 18:04:06,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:06,318:INFO:Checking exceptions
2023-01-09 18:04:06,318:INFO:Importing libraries
2023-01-09 18:04:06,318:INFO:Copying training dataset
2023-01-09 18:04:06,322:INFO:Defining folds
2023-01-09 18:04:06,322:INFO:Declaring metric variables
2023-01-09 18:04:06,323:INFO:Importing untrained model
2023-01-09 18:04:06,323:INFO:Bayesian Ridge Imported successfully
2023-01-09 18:04:06,324:INFO:Starting cross validation
2023-01-09 18:04:06,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:06,481:INFO:Calculating mean and std
2023-01-09 18:04:06,482:INFO:Creating metrics dataframe
2023-01-09 18:04:06,486:INFO:Uploading results into container
2023-01-09 18:04:06,486:INFO:Uploading model into container now
2023-01-09 18:04:06,487:INFO:_master_model_container: 8
2023-01-09 18:04:06,487:INFO:_display_container: 2
2023-01-09 18:04:06,487:INFO:BayesianRidge()
2023-01-09 18:04:06,487:INFO:create_model() successfully completed......................................
2023-01-09 18:04:06,582:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:06,583:INFO:Creating metrics dataframe
2023-01-09 18:04:06,588:INFO:Initializing Passive Aggressive Regressor
2023-01-09 18:04:06,588:INFO:Total runtime is 0.11493529876073201 minutes
2023-01-09 18:04:06,588:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:06,589:INFO:Initializing create_model()
2023-01-09 18:04:06,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:06,589:INFO:Checking exceptions
2023-01-09 18:04:06,589:INFO:Importing libraries
2023-01-09 18:04:06,589:INFO:Copying training dataset
2023-01-09 18:04:06,593:INFO:Defining folds
2023-01-09 18:04:06,593:INFO:Declaring metric variables
2023-01-09 18:04:06,593:INFO:Importing untrained model
2023-01-09 18:04:06,594:INFO:Passive Aggressive Regressor Imported successfully
2023-01-09 18:04:06,594:INFO:Starting cross validation
2023-01-09 18:04:06,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:06,783:INFO:Calculating mean and std
2023-01-09 18:04:06,783:INFO:Creating metrics dataframe
2023-01-09 18:04:06,792:INFO:Uploading results into container
2023-01-09 18:04:06,793:INFO:Uploading model into container now
2023-01-09 18:04:06,793:INFO:_master_model_container: 9
2023-01-09 18:04:06,793:INFO:_display_container: 2
2023-01-09 18:04:06,794:INFO:PassiveAggressiveRegressor(random_state=2540)
2023-01-09 18:04:06,794:INFO:create_model() successfully completed......................................
2023-01-09 18:04:06,898:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:06,898:INFO:Creating metrics dataframe
2023-01-09 18:04:06,914:INFO:Initializing Huber Regressor
2023-01-09 18:04:06,914:INFO:Total runtime is 0.12035990953445434 minutes
2023-01-09 18:04:06,915:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:06,915:INFO:Initializing create_model()
2023-01-09 18:04:06,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:06,915:INFO:Checking exceptions
2023-01-09 18:04:06,915:INFO:Importing libraries
2023-01-09 18:04:06,915:INFO:Copying training dataset
2023-01-09 18:04:06,919:INFO:Defining folds
2023-01-09 18:04:06,919:INFO:Declaring metric variables
2023-01-09 18:04:06,920:INFO:Importing untrained model
2023-01-09 18:04:06,920:INFO:Huber Regressor Imported successfully
2023-01-09 18:04:06,920:INFO:Starting cross validation
2023-01-09 18:04:06,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:07,546:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,560:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,565:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,589:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,652:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,754:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,768:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,768:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,978:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,984:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:07,997:INFO:Calculating mean and std
2023-01-09 18:04:07,997:INFO:Creating metrics dataframe
2023-01-09 18:04:08,005:INFO:Uploading results into container
2023-01-09 18:04:08,006:INFO:Uploading model into container now
2023-01-09 18:04:08,007:INFO:_master_model_container: 10
2023-01-09 18:04:08,007:INFO:_display_container: 2
2023-01-09 18:04:08,008:INFO:HuberRegressor()
2023-01-09 18:04:08,008:INFO:create_model() successfully completed......................................
2023-01-09 18:04:08,114:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:08,114:INFO:Creating metrics dataframe
2023-01-09 18:04:08,114:INFO:Initializing K Neighbors Regressor
2023-01-09 18:04:08,114:INFO:Total runtime is 0.14036333560943604 minutes
2023-01-09 18:04:08,114:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:08,114:INFO:Initializing create_model()
2023-01-09 18:04:08,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:08,114:INFO:Checking exceptions
2023-01-09 18:04:08,114:INFO:Importing libraries
2023-01-09 18:04:08,114:INFO:Copying training dataset
2023-01-09 18:04:08,122:INFO:Defining folds
2023-01-09 18:04:08,122:INFO:Declaring metric variables
2023-01-09 18:04:08,122:INFO:Importing untrained model
2023-01-09 18:04:08,122:INFO:K Neighbors Regressor Imported successfully
2023-01-09 18:04:08,129:INFO:Starting cross validation
2023-01-09 18:04:08,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:08,367:INFO:Calculating mean and std
2023-01-09 18:04:08,367:INFO:Creating metrics dataframe
2023-01-09 18:04:08,372:INFO:Uploading results into container
2023-01-09 18:04:08,373:INFO:Uploading model into container now
2023-01-09 18:04:08,374:INFO:_master_model_container: 11
2023-01-09 18:04:08,374:INFO:_display_container: 2
2023-01-09 18:04:08,375:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-09 18:04:08,375:INFO:create_model() successfully completed......................................
2023-01-09 18:04:08,464:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:08,464:INFO:Creating metrics dataframe
2023-01-09 18:04:08,481:INFO:Initializing Decision Tree Regressor
2023-01-09 18:04:08,481:INFO:Total runtime is 0.14647679726282756 minutes
2023-01-09 18:04:08,481:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:08,481:INFO:Initializing create_model()
2023-01-09 18:04:08,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:08,481:INFO:Checking exceptions
2023-01-09 18:04:08,481:INFO:Importing libraries
2023-01-09 18:04:08,481:INFO:Copying training dataset
2023-01-09 18:04:08,481:INFO:Defining folds
2023-01-09 18:04:08,481:INFO:Declaring metric variables
2023-01-09 18:04:08,481:INFO:Importing untrained model
2023-01-09 18:04:08,491:INFO:Decision Tree Regressor Imported successfully
2023-01-09 18:04:08,491:INFO:Starting cross validation
2023-01-09 18:04:08,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:08,878:INFO:Calculating mean and std
2023-01-09 18:04:08,879:INFO:Creating metrics dataframe
2023-01-09 18:04:08,885:INFO:Uploading results into container
2023-01-09 18:04:08,886:INFO:Uploading model into container now
2023-01-09 18:04:08,887:INFO:_master_model_container: 12
2023-01-09 18:04:08,888:INFO:_display_container: 2
2023-01-09 18:04:08,888:INFO:DecisionTreeRegressor(random_state=2540)
2023-01-09 18:04:08,888:INFO:create_model() successfully completed......................................
2023-01-09 18:04:08,987:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:08,988:INFO:Creating metrics dataframe
2023-01-09 18:04:08,993:INFO:Initializing Random Forest Regressor
2023-01-09 18:04:08,994:INFO:Total runtime is 0.15502506097157798 minutes
2023-01-09 18:04:08,994:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:08,994:INFO:Initializing create_model()
2023-01-09 18:04:08,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:08,995:INFO:Checking exceptions
2023-01-09 18:04:08,995:INFO:Importing libraries
2023-01-09 18:04:08,995:INFO:Copying training dataset
2023-01-09 18:04:09,005:INFO:Defining folds
2023-01-09 18:04:09,005:INFO:Declaring metric variables
2023-01-09 18:04:09,005:INFO:Importing untrained model
2023-01-09 18:04:09,007:INFO:Random Forest Regressor Imported successfully
2023-01-09 18:04:09,007:INFO:Starting cross validation
2023-01-09 18:04:09,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:19,407:INFO:PyCaret RegressionExperiment
2023-01-09 18:04:19,407:INFO:Logging name: reg-default-name
2023-01-09 18:04:19,407:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-09 18:04:19,407:INFO:version 3.0.0.rc7
2023-01-09 18:04:19,407:INFO:Initializing setup()
2023-01-09 18:04:19,408:INFO:self.USI: cfaa
2023-01-09 18:04:19,408:INFO:self._variable_keys: {'exp_id', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'idx', 'X_test', 'seed', 'gpu_n_jobs_param', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'y', 'target_param', '_available_plots', 'html_param', 'memory', 'data', 'exp_name_log', 'fold_generator', 'pipeline', 'USI', 'fold_shuffle_param', 'X_train', 'logging_param', 'transform_target_param'}
2023-01-09 18:04:19,408:INFO:Checking environment
2023-01-09 18:04:19,408:INFO:python_version: 3.10.5
2023-01-09 18:04:19,408:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-01-09 18:04:19,408:INFO:machine: AMD64
2023-01-09 18:04:19,409:INFO:platform: Windows-10-10.0.19045-SP0
2023-01-09 18:04:19,413:INFO:Memory: svmem(total=8494747648, available=1341202432, percent=84.2, used=7153545216, free=1341202432)
2023-01-09 18:04:19,414:INFO:Physical Core: 4
2023-01-09 18:04:19,414:INFO:Logical Core: 8
2023-01-09 18:04:19,414:INFO:Checking libraries
2023-01-09 18:04:19,414:INFO:System:
2023-01-09 18:04:19,414:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-01-09 18:04:19,414:INFO:executable: C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\Scripts\python.exe
2023-01-09 18:04:19,415:INFO:   machine: Windows-10-10.0.19045-SP0
2023-01-09 18:04:19,415:INFO:PyCaret required dependencies:
2023-01-09 18:04:19,415:INFO:                 pip: 22.3.1
2023-01-09 18:04:19,415:INFO:          setuptools: 58.1.0
2023-01-09 18:04:19,415:INFO:             pycaret: 3.0.0rc7
2023-01-09 18:04:19,415:INFO:             IPython: 8.8.0
2023-01-09 18:04:19,416:INFO:          ipywidgets: 8.0.4
2023-01-09 18:04:19,416:INFO:                tqdm: 4.64.1
2023-01-09 18:04:19,416:INFO:               numpy: 1.23.5
2023-01-09 18:04:19,416:INFO:              pandas: 1.5.2
2023-01-09 18:04:19,416:INFO:              jinja2: 3.1.2
2023-01-09 18:04:19,416:INFO:               scipy: 1.9.3
2023-01-09 18:04:19,416:INFO:              joblib: 1.2.0
2023-01-09 18:04:19,417:INFO:             sklearn: 1.1.3
2023-01-09 18:04:19,417:INFO:                pyod: 1.0.7
2023-01-09 18:04:19,417:INFO:            imblearn: 0.10.1
2023-01-09 18:04:19,417:INFO:   category_encoders: 2.5.1.post0
2023-01-09 18:04:19,418:INFO:            lightgbm: 3.3.4
2023-01-09 18:04:19,418:INFO:               numba: 0.56.4
2023-01-09 18:04:19,418:INFO:            requests: 2.28.1
2023-01-09 18:04:19,418:INFO:          matplotlib: 3.6.2
2023-01-09 18:04:19,418:INFO:          scikitplot: 0.3.7
2023-01-09 18:04:19,418:INFO:         yellowbrick: 1.5
2023-01-09 18:04:19,419:INFO:              plotly: 5.11.0
2023-01-09 18:04:19,419:INFO:             kaleido: 0.2.1
2023-01-09 18:04:19,419:INFO:         statsmodels: 0.13.5
2023-01-09 18:04:19,420:INFO:              sktime: 0.15.0
2023-01-09 18:04:19,420:INFO:               tbats: 1.1.2
2023-01-09 18:04:19,420:INFO:            pmdarima: 2.0.2
2023-01-09 18:04:19,420:INFO:              psutil: 5.9.4
2023-01-09 18:04:19,420:INFO:PyCaret optional dependencies:
2023-01-09 18:04:19,421:INFO:                shap: Not installed
2023-01-09 18:04:19,421:INFO:           interpret: Not installed
2023-01-09 18:04:19,421:INFO:                umap: Not installed
2023-01-09 18:04:19,421:INFO:    pandas_profiling: 3.6.2
2023-01-09 18:04:19,421:INFO:  explainerdashboard: Not installed
2023-01-09 18:04:19,421:INFO:             autoviz: Not installed
2023-01-09 18:04:19,422:INFO:           fairlearn: Not installed
2023-01-09 18:04:19,422:INFO:             xgboost: Not installed
2023-01-09 18:04:19,422:INFO:            catboost: Not installed
2023-01-09 18:04:19,422:INFO:              kmodes: Not installed
2023-01-09 18:04:19,422:INFO:             mlxtend: Not installed
2023-01-09 18:04:19,422:INFO:       statsforecast: Not installed
2023-01-09 18:04:19,422:INFO:        tune_sklearn: Not installed
2023-01-09 18:04:19,423:INFO:                 ray: Not installed
2023-01-09 18:04:19,423:INFO:            hyperopt: Not installed
2023-01-09 18:04:19,423:INFO:              optuna: Not installed
2023-01-09 18:04:19,423:INFO:               skopt: Not installed
2023-01-09 18:04:19,423:INFO:              mlflow: Not installed
2023-01-09 18:04:19,423:INFO:              gradio: Not installed
2023-01-09 18:04:19,423:INFO:             fastapi: Not installed
2023-01-09 18:04:19,430:INFO:             uvicorn: Not installed
2023-01-09 18:04:19,438:INFO:              m2cgen: Not installed
2023-01-09 18:04:19,442:INFO:           evidently: Not installed
2023-01-09 18:04:19,445:INFO:                nltk: Not installed
2023-01-09 18:04:19,446:INFO:            pyLDAvis: Not installed
2023-01-09 18:04:19,447:INFO:              gensim: Not installed
2023-01-09 18:04:19,448:INFO:               spacy: Not installed
2023-01-09 18:04:19,448:INFO:           wordcloud: Not installed
2023-01-09 18:04:19,448:INFO:            textblob: Not installed
2023-01-09 18:04:19,448:INFO:               fugue: Not installed
2023-01-09 18:04:19,453:INFO:           streamlit: 1.16.0
2023-01-09 18:04:19,453:INFO:             prophet: Not installed
2023-01-09 18:04:19,454:INFO:None
2023-01-09 18:04:19,454:INFO:Set up data.
2023-01-09 18:04:19,480:INFO:Set up train/test split.
2023-01-09 18:04:19,515:INFO:Set up index.
2023-01-09 18:04:19,515:INFO:Set up folding strategy.
2023-01-09 18:04:19,516:INFO:Assigning column types.
2023-01-09 18:04:19,528:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-09 18:04:19,529:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:04:19,547:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:04:19,562:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:19,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:20,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:20,102:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,860:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:20,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:20,860:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-09 18:04:20,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:04:20,920:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:21,293:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:21,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:21,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:21,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:21,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-09 18:04:21,596:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:21,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:22,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:22,290:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-09 18:04:22,312:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:22,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:22,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-09 18:04:22,816:INFO:Calculating mean and std
2023-01-09 18:04:22,816:INFO:Creating metrics dataframe
2023-01-09 18:04:22,828:INFO:Uploading results into container
2023-01-09 18:04:22,832:INFO:Uploading model into container now
2023-01-09 18:04:22,833:INFO:_master_model_container: 13
2023-01-09 18:04:22,833:INFO:_display_container: 2
2023-01-09 18:04:22,833:INFO:RandomForestRegressor(n_jobs=-1, random_state=2540)
2023-01-09 18:04:22,834:INFO:create_model() successfully completed......................................
2023-01-09 18:04:22,964:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:22,964:INFO:Creating metrics dataframe
2023-01-09 18:04:22,971:INFO:Initializing Extra Trees Regressor
2023-01-09 18:04:22,971:INFO:Total runtime is 0.3879799207051595 minutes
2023-01-09 18:04:22,971:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:22,972:INFO:Initializing create_model()
2023-01-09 18:04:22,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:22,972:INFO:Checking exceptions
2023-01-09 18:04:22,972:INFO:Importing libraries
2023-01-09 18:04:22,972:INFO:Copying training dataset
2023-01-09 18:04:23,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,085:INFO:Defining folds
2023-01-09 18:04:23,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,100:INFO:Declaring metric variables
2023-01-09 18:04:23,100:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-09 18:04:23,101:INFO:Importing untrained model
2023-01-09 18:04:23,128:INFO:Extra Trees Regressor Imported successfully
2023-01-09 18:04:23,128:INFO:Starting cross validation
2023-01-09 18:04:23,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:23,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,440:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-09 18:04:23,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:23,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:23,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:24,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-09 18:04:25,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:25,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:25,713:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-09 18:04:27,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:27,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:28,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:28,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:28,846:INFO:Preparing preprocessing pipeline...
2023-01-09 18:04:28,846:INFO:Set up simple imputation.
2023-01-09 18:04:29,028:INFO:Finished creating preprocessing pipeline.
2023-01-09 18:04:29,040:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-09 18:04:29,041:INFO:Creating final display dataframe.
2023-01-09 18:04:30,759:INFO:Setup _display_container:                     Description             Value
0                    Session id              2574
1                        Target       MedHouseVal
2                   Target type        Regression
3           Original data shape        (15480, 9)
4        Transformed data shape        (15480, 9)
5   Transformed train set shape        (10836, 9)
6    Transformed test set shape         (4644, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              cfaa
2023-01-09 18:04:30,763:INFO:                    Description             Value
0                    Session id              2574
1                        Target       MedHouseVal
2                   Target type        Regression
3           Original data shape        (15480, 9)
4        Transformed data shape        (15480, 9)
5   Transformed train set shape        (10836, 9)
6    Transformed test set shape         (4644, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              cfaa
2023-01-09 18:04:31,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:31,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:31,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:31,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-09 18:04:31,631:INFO:setup() successfully completed in 12.23s...............
2023-01-09 18:04:31,635:INFO:Calculating mean and std
2023-01-09 18:04:31,638:INFO:Creating metrics dataframe
2023-01-09 18:04:31,639:INFO:Initializing compare_models()
2023-01-09 18:04:31,646:INFO:Uploading results into container
2023-01-09 18:04:31,646:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-09 18:04:31,648:INFO:Uploading model into container now
2023-01-09 18:04:31,649:INFO:Checking exceptions
2023-01-09 18:04:31,650:INFO:_master_model_container: 14
2023-01-09 18:04:31,655:INFO:_display_container: 2
2023-01-09 18:04:31,655:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2540)
2023-01-09 18:04:31,655:INFO:create_model() successfully completed......................................
2023-01-09 18:04:31,788:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:31,788:INFO:Creating metrics dataframe
2023-01-09 18:04:31,791:INFO:Initializing AdaBoost Regressor
2023-01-09 18:04:31,791:INFO:Total runtime is 0.534975802898407 minutes
2023-01-09 18:04:31,797:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:31,797:INFO:Initializing create_model()
2023-01-09 18:04:31,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:31,797:INFO:Checking exceptions
2023-01-09 18:04:31,797:INFO:Importing libraries
2023-01-09 18:04:31,797:INFO:Copying training dataset
2023-01-09 18:04:31,797:INFO:Preparing display monitor
2023-01-09 18:04:31,801:INFO:Initializing Linear Regression
2023-01-09 18:04:31,803:INFO:Total runtime is 3.153880437215169e-05 minutes
2023-01-09 18:04:31,803:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:31,803:INFO:Initializing create_model()
2023-01-09 18:04:31,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:31,803:INFO:Checking exceptions
2023-01-09 18:04:31,804:INFO:Importing libraries
2023-01-09 18:04:31,807:INFO:Copying training dataset
2023-01-09 18:04:31,813:INFO:Defining folds
2023-01-09 18:04:31,813:INFO:Declaring metric variables
2023-01-09 18:04:31,814:INFO:Importing untrained model
2023-01-09 18:04:31,814:INFO:AdaBoost Regressor Imported successfully
2023-01-09 18:04:31,814:INFO:Starting cross validation
2023-01-09 18:04:31,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:31,822:INFO:Defining folds
2023-01-09 18:04:31,822:INFO:Declaring metric variables
2023-01-09 18:04:31,823:INFO:Importing untrained model
2023-01-09 18:04:31,823:INFO:Linear Regression Imported successfully
2023-01-09 18:04:31,824:INFO:Starting cross validation
2023-01-09 18:04:31,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:33,784:INFO:Calculating mean and std
2023-01-09 18:04:33,784:INFO:Creating metrics dataframe
2023-01-09 18:04:33,797:INFO:Uploading results into container
2023-01-09 18:04:33,798:INFO:Uploading model into container now
2023-01-09 18:04:33,799:INFO:_master_model_container: 1
2023-01-09 18:04:33,799:INFO:_display_container: 2
2023-01-09 18:04:33,799:INFO:LinearRegression(n_jobs=-1)
2023-01-09 18:04:33,800:INFO:create_model() successfully completed......................................
2023-01-09 18:04:33,922:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:33,922:INFO:Creating metrics dataframe
2023-01-09 18:04:33,925:INFO:Initializing Lasso Regression
2023-01-09 18:04:33,925:INFO:Total runtime is 0.035389244556427 minutes
2023-01-09 18:04:33,925:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:33,925:INFO:Initializing create_model()
2023-01-09 18:04:33,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:33,925:INFO:Checking exceptions
2023-01-09 18:04:33,925:INFO:Importing libraries
2023-01-09 18:04:33,925:INFO:Copying training dataset
2023-01-09 18:04:33,935:INFO:Defining folds
2023-01-09 18:04:33,935:INFO:Declaring metric variables
2023-01-09 18:04:33,935:INFO:Importing untrained model
2023-01-09 18:04:33,937:INFO:Lasso Regression Imported successfully
2023-01-09 18:04:33,937:INFO:Starting cross validation
2023-01-09 18:04:33,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:34,145:INFO:Calculating mean and std
2023-01-09 18:04:34,147:INFO:Creating metrics dataframe
2023-01-09 18:04:34,153:INFO:Uploading results into container
2023-01-09 18:04:34,155:INFO:Uploading model into container now
2023-01-09 18:04:34,156:INFO:_master_model_container: 2
2023-01-09 18:04:34,156:INFO:_display_container: 2
2023-01-09 18:04:34,156:INFO:Lasso(random_state=2574)
2023-01-09 18:04:34,156:INFO:create_model() successfully completed......................................
2023-01-09 18:04:34,278:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:34,278:INFO:Creating metrics dataframe
2023-01-09 18:04:34,286:INFO:Initializing Ridge Regression
2023-01-09 18:04:34,286:INFO:Total runtime is 0.0414215882619222 minutes
2023-01-09 18:04:34,289:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:34,289:INFO:Initializing create_model()
2023-01-09 18:04:34,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:34,289:INFO:Checking exceptions
2023-01-09 18:04:34,289:INFO:Importing libraries
2023-01-09 18:04:34,289:INFO:Copying training dataset
2023-01-09 18:04:34,289:INFO:Defining folds
2023-01-09 18:04:34,289:INFO:Declaring metric variables
2023-01-09 18:04:34,289:INFO:Importing untrained model
2023-01-09 18:04:34,295:INFO:Ridge Regression Imported successfully
2023-01-09 18:04:34,296:INFO:Starting cross validation
2023-01-09 18:04:34,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:34,361:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.55792e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,374:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.56265e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,391:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.63489e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,404:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.5809e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,420:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.58126e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,430:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.5846e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,440:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.52376e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,448:INFO:Calculating mean and std
2023-01-09 18:04:34,450:INFO:Creating metrics dataframe
2023-01-09 18:04:34,459:INFO:Uploading results into container
2023-01-09 18:04:34,460:INFO:Uploading model into container now
2023-01-09 18:04:34,461:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.67999e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,461:INFO:_master_model_container: 15
2023-01-09 18:04:34,462:INFO:_display_container: 2
2023-01-09 18:04:34,462:INFO:AdaBoostRegressor(random_state=2540)
2023-01-09 18:04:34,462:INFO:create_model() successfully completed......................................
2023-01-09 18:04:34,475:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.44917e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,593:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:34,595:INFO:Creating metrics dataframe
2023-01-09 18:04:34,615:INFO:Initializing Gradient Boosting Regressor
2023-01-09 18:04:34,615:INFO:Total runtime is 0.5820485671361287 minutes
2023-01-09 18:04:34,616:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:34,617:INFO:Initializing create_model()
2023-01-09 18:04:34,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:34,617:INFO:Checking exceptions
2023-01-09 18:04:34,618:INFO:Importing libraries
2023-01-09 18:04:34,618:INFO:Copying training dataset
2023-01-09 18:04:34,627:INFO:Defining folds
2023-01-09 18:04:34,628:INFO:Declaring metric variables
2023-01-09 18:04:34,628:INFO:Importing untrained model
2023-01-09 18:04:34,629:INFO:Gradient Boosting Regressor Imported successfully
2023-01-09 18:04:34,630:INFO:Starting cross validation
2023-01-09 18:04:34,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:34,633:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.59935e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-09 18:04:34,652:INFO:Calculating mean and std
2023-01-09 18:04:34,654:INFO:Creating metrics dataframe
2023-01-09 18:04:34,660:INFO:Uploading results into container
2023-01-09 18:04:34,660:INFO:Uploading model into container now
2023-01-09 18:04:34,660:INFO:_master_model_container: 3
2023-01-09 18:04:34,660:INFO:_display_container: 2
2023-01-09 18:04:34,660:INFO:Ridge(random_state=2574)
2023-01-09 18:04:34,660:INFO:create_model() successfully completed......................................
2023-01-09 18:04:34,863:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:34,863:INFO:Creating metrics dataframe
2023-01-09 18:04:34,881:INFO:Initializing Elastic Net
2023-01-09 18:04:34,882:INFO:Total runtime is 0.05134665171305339 minutes
2023-01-09 18:04:34,882:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:34,884:INFO:Initializing create_model()
2023-01-09 18:04:34,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:34,887:INFO:Checking exceptions
2023-01-09 18:04:34,887:INFO:Importing libraries
2023-01-09 18:04:34,888:INFO:Copying training dataset
2023-01-09 18:04:34,986:INFO:Defining folds
2023-01-09 18:04:34,991:INFO:Declaring metric variables
2023-01-09 18:04:34,993:INFO:Importing untrained model
2023-01-09 18:04:34,996:INFO:Elastic Net Imported successfully
2023-01-09 18:04:35,010:INFO:Starting cross validation
2023-01-09 18:04:35,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:38,922:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 18:04:39,989:INFO:Calculating mean and std
2023-01-09 18:04:39,996:INFO:Creating metrics dataframe
2023-01-09 18:04:40,008:INFO:Uploading results into container
2023-01-09 18:04:40,010:INFO:Uploading model into container now
2023-01-09 18:04:40,012:INFO:_master_model_container: 4
2023-01-09 18:04:40,012:INFO:_display_container: 2
2023-01-09 18:04:40,013:INFO:ElasticNet(random_state=2574)
2023-01-09 18:04:40,013:INFO:create_model() successfully completed......................................
2023-01-09 18:04:40,176:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:40,176:INFO:Creating metrics dataframe
2023-01-09 18:04:40,188:INFO:Initializing Least Angle Regression
2023-01-09 18:04:40,189:INFO:Total runtime is 0.13979643185933432 minutes
2023-01-09 18:04:40,189:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:40,189:INFO:Initializing create_model()
2023-01-09 18:04:40,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:40,189:INFO:Checking exceptions
2023-01-09 18:04:40,189:INFO:Importing libraries
2023-01-09 18:04:40,189:INFO:Copying training dataset
2023-01-09 18:04:40,229:INFO:Defining folds
2023-01-09 18:04:40,229:INFO:Declaring metric variables
2023-01-09 18:04:40,231:INFO:Importing untrained model
2023-01-09 18:04:40,231:INFO:Least Angle Regression Imported successfully
2023-01-09 18:04:40,234:INFO:Starting cross validation
2023-01-09 18:04:40,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:40,380:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,398:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,432:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,522:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,558:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,579:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,594:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,623:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,662:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,687:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:40,723:INFO:Calculating mean and std
2023-01-09 18:04:40,724:INFO:Creating metrics dataframe
2023-01-09 18:04:40,732:INFO:Uploading results into container
2023-01-09 18:04:40,733:INFO:Uploading model into container now
2023-01-09 18:04:40,733:INFO:_master_model_container: 5
2023-01-09 18:04:40,734:INFO:_display_container: 2
2023-01-09 18:04:40,734:INFO:Lars(random_state=2574)
2023-01-09 18:04:40,735:INFO:create_model() successfully completed......................................
2023-01-09 18:04:40,863:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:40,864:INFO:Creating metrics dataframe
2023-01-09 18:04:40,873:INFO:Initializing Lasso Least Angle Regression
2023-01-09 18:04:40,873:INFO:Total runtime is 0.15120289723078412 minutes
2023-01-09 18:04:40,873:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:40,874:INFO:Initializing create_model()
2023-01-09 18:04:40,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:40,874:INFO:Checking exceptions
2023-01-09 18:04:40,874:INFO:Importing libraries
2023-01-09 18:04:40,874:INFO:Copying training dataset
2023-01-09 18:04:40,897:INFO:Defining folds
2023-01-09 18:04:40,902:INFO:Declaring metric variables
2023-01-09 18:04:40,903:INFO:Importing untrained model
2023-01-09 18:04:40,903:INFO:Lasso Least Angle Regression Imported successfully
2023-01-09 18:04:40,904:INFO:Starting cross validation
2023-01-09 18:04:40,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:41,016:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,041:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,070:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,088:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,112:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,131:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,180:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,197:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,211:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,229:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-09 18:04:41,240:INFO:Calculating mean and std
2023-01-09 18:04:41,249:INFO:Creating metrics dataframe
2023-01-09 18:04:41,259:INFO:Uploading results into container
2023-01-09 18:04:41,260:INFO:Uploading model into container now
2023-01-09 18:04:41,261:INFO:_master_model_container: 6
2023-01-09 18:04:41,261:INFO:_display_container: 2
2023-01-09 18:04:41,262:INFO:LassoLars(random_state=2574)
2023-01-09 18:04:41,262:INFO:create_model() successfully completed......................................
2023-01-09 18:04:41,384:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:41,385:INFO:Creating metrics dataframe
2023-01-09 18:04:41,394:INFO:Initializing Orthogonal Matching Pursuit
2023-01-09 18:04:41,394:INFO:Total runtime is 0.15987783273061118 minutes
2023-01-09 18:04:41,394:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:41,396:INFO:Initializing create_model()
2023-01-09 18:04:41,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:41,396:INFO:Checking exceptions
2023-01-09 18:04:41,402:INFO:Importing libraries
2023-01-09 18:04:41,402:INFO:Copying training dataset
2023-01-09 18:04:41,448:INFO:Defining folds
2023-01-09 18:04:41,448:INFO:Declaring metric variables
2023-01-09 18:04:41,448:INFO:Importing untrained model
2023-01-09 18:04:41,449:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-09 18:04:41,450:INFO:Starting cross validation
2023-01-09 18:04:41,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:41,572:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,572:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,619:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,639:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,658:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,673:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,721:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,736:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,736:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,759:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-09 18:04:41,775:INFO:Calculating mean and std
2023-01-09 18:04:41,791:INFO:Creating metrics dataframe
2023-01-09 18:04:41,796:INFO:Uploading results into container
2023-01-09 18:04:41,799:INFO:Uploading model into container now
2023-01-09 18:04:41,800:INFO:_master_model_container: 7
2023-01-09 18:04:41,800:INFO:_display_container: 2
2023-01-09 18:04:41,802:INFO:OrthogonalMatchingPursuit()
2023-01-09 18:04:41,802:INFO:create_model() successfully completed......................................
2023-01-09 18:04:41,950:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:41,950:INFO:Creating metrics dataframe
2023-01-09 18:04:41,958:INFO:Initializing Bayesian Ridge
2023-01-09 18:04:41,959:INFO:Total runtime is 0.16930201053619387 minutes
2023-01-09 18:04:41,959:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:41,960:INFO:Initializing create_model()
2023-01-09 18:04:41,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:41,960:INFO:Checking exceptions
2023-01-09 18:04:41,961:INFO:Importing libraries
2023-01-09 18:04:41,961:INFO:Copying training dataset
2023-01-09 18:04:42,004:INFO:Defining folds
2023-01-09 18:04:42,004:INFO:Declaring metric variables
2023-01-09 18:04:42,005:INFO:Importing untrained model
2023-01-09 18:04:42,005:INFO:Bayesian Ridge Imported successfully
2023-01-09 18:04:42,006:INFO:Starting cross validation
2023-01-09 18:04:42,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:42,322:INFO:Calculating mean and std
2023-01-09 18:04:42,336:INFO:Creating metrics dataframe
2023-01-09 18:04:42,343:INFO:Uploading results into container
2023-01-09 18:04:42,344:INFO:Uploading model into container now
2023-01-09 18:04:42,345:INFO:_master_model_container: 8
2023-01-09 18:04:42,345:INFO:_display_container: 2
2023-01-09 18:04:42,346:INFO:BayesianRidge()
2023-01-09 18:04:42,346:INFO:create_model() successfully completed......................................
2023-01-09 18:04:42,469:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:42,470:INFO:Creating metrics dataframe
2023-01-09 18:04:42,472:INFO:Initializing Passive Aggressive Regressor
2023-01-09 18:04:42,472:INFO:Total runtime is 0.1778474013010661 minutes
2023-01-09 18:04:42,472:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:42,472:INFO:Initializing create_model()
2023-01-09 18:04:42,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:42,472:INFO:Checking exceptions
2023-01-09 18:04:42,472:INFO:Importing libraries
2023-01-09 18:04:42,472:INFO:Copying training dataset
2023-01-09 18:04:42,522:INFO:Defining folds
2023-01-09 18:04:42,523:INFO:Declaring metric variables
2023-01-09 18:04:42,523:INFO:Importing untrained model
2023-01-09 18:04:42,524:INFO:Passive Aggressive Regressor Imported successfully
2023-01-09 18:04:42,525:INFO:Starting cross validation
2023-01-09 18:04:42,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:42,732:INFO:Calculating mean and std
2023-01-09 18:04:42,743:INFO:Creating metrics dataframe
2023-01-09 18:04:42,750:INFO:Uploading results into container
2023-01-09 18:04:42,753:INFO:Uploading model into container now
2023-01-09 18:04:42,756:INFO:_master_model_container: 16
2023-01-09 18:04:42,757:INFO:_display_container: 2
2023-01-09 18:04:42,758:INFO:GradientBoostingRegressor(random_state=2540)
2023-01-09 18:04:42,759:INFO:create_model() successfully completed......................................
2023-01-09 18:04:42,872:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:42,872:INFO:Creating metrics dataframe
2023-01-09 18:04:42,879:INFO:Initializing Light Gradient Boosting Machine
2023-01-09 18:04:42,880:INFO:Total runtime is 0.7197700540224711 minutes
2023-01-09 18:04:42,880:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:42,880:INFO:Initializing create_model()
2023-01-09 18:04:42,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:42,880:INFO:Checking exceptions
2023-01-09 18:04:42,880:INFO:Importing libraries
2023-01-09 18:04:42,880:INFO:Copying training dataset
2023-01-09 18:04:42,924:INFO:Defining folds
2023-01-09 18:04:42,940:INFO:Declaring metric variables
2023-01-09 18:04:42,940:INFO:Importing untrained model
2023-01-09 18:04:42,941:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:04:42,941:INFO:Starting cross validation
2023-01-09 18:04:42,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:42,956:INFO:Calculating mean and std
2023-01-09 18:04:42,960:INFO:Creating metrics dataframe
2023-01-09 18:04:42,965:INFO:Uploading results into container
2023-01-09 18:04:42,965:INFO:Uploading model into container now
2023-01-09 18:04:42,966:INFO:_master_model_container: 9
2023-01-09 18:04:42,966:INFO:_display_container: 2
2023-01-09 18:04:42,966:INFO:PassiveAggressiveRegressor(random_state=2574)
2023-01-09 18:04:42,966:INFO:create_model() successfully completed......................................
2023-01-09 18:04:43,071:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:43,071:INFO:Creating metrics dataframe
2023-01-09 18:04:43,073:INFO:Initializing Huber Regressor
2023-01-09 18:04:43,073:INFO:Total runtime is 0.18786701758702598 minutes
2023-01-09 18:04:43,073:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:43,073:INFO:Initializing create_model()
2023-01-09 18:04:43,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:43,073:INFO:Checking exceptions
2023-01-09 18:04:43,073:INFO:Importing libraries
2023-01-09 18:04:43,073:INFO:Copying training dataset
2023-01-09 18:04:43,108:INFO:Defining folds
2023-01-09 18:04:43,108:INFO:Declaring metric variables
2023-01-09 18:04:43,109:INFO:Importing untrained model
2023-01-09 18:04:43,109:INFO:Huber Regressor Imported successfully
2023-01-09 18:04:43,109:INFO:Starting cross validation
2023-01-09 18:04:43,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:44,176:INFO:Calculating mean and std
2023-01-09 18:04:44,176:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,199:INFO:Creating metrics dataframe
2023-01-09 18:04:44,218:INFO:Uploading results into container
2023-01-09 18:04:44,221:INFO:Uploading model into container now
2023-01-09 18:04:44,225:INFO:_master_model_container: 17
2023-01-09 18:04:44,225:INFO:_display_container: 2
2023-01-09 18:04:44,227:INFO:LGBMRegressor(random_state=2540)
2023-01-09 18:04:44,228:INFO:create_model() successfully completed......................................
2023-01-09 18:04:44,248:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,336:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,415:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,441:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,483:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,523:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,574:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:44,574:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,574:INFO:Creating metrics dataframe
2023-01-09 18:04:44,584:INFO:Initializing Dummy Regressor
2023-01-09 18:04:44,584:INFO:Total runtime is 0.7481936494509379 minutes
2023-01-09 18:04:44,584:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:44,584:INFO:Initializing create_model()
2023-01-09 18:04:44,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26B0E1ED0>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:44,584:INFO:Checking exceptions
2023-01-09 18:04:44,584:INFO:Importing libraries
2023-01-09 18:04:44,584:INFO:Copying training dataset
2023-01-09 18:04:44,594:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,623:INFO:Defining folds
2023-01-09 18:04:44,623:INFO:Declaring metric variables
2023-01-09 18:04:44,625:INFO:Importing untrained model
2023-01-09 18:04:44,625:INFO:Dummy Regressor Imported successfully
2023-01-09 18:04:44,626:INFO:Starting cross validation
2023-01-09 18:04:44,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:44,766:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-09 18:04:44,817:INFO:Calculating mean and std
2023-01-09 18:04:44,817:INFO:Creating metrics dataframe
2023-01-09 18:04:44,825:INFO:Uploading results into container
2023-01-09 18:04:44,825:INFO:Uploading model into container now
2023-01-09 18:04:44,825:INFO:_master_model_container: 10
2023-01-09 18:04:44,825:INFO:_display_container: 2
2023-01-09 18:04:44,825:INFO:HuberRegressor()
2023-01-09 18:04:44,825:INFO:create_model() successfully completed......................................
2023-01-09 18:04:44,935:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:44,935:INFO:Creating metrics dataframe
2023-01-09 18:04:44,935:INFO:Initializing K Neighbors Regressor
2023-01-09 18:04:44,935:INFO:Total runtime is 0.21890412171681725 minutes
2023-01-09 18:04:44,935:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:44,935:INFO:Initializing create_model()
2023-01-09 18:04:44,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:44,935:INFO:Checking exceptions
2023-01-09 18:04:44,935:INFO:Importing libraries
2023-01-09 18:04:44,935:INFO:Copying training dataset
2023-01-09 18:04:44,967:INFO:Defining folds
2023-01-09 18:04:44,967:INFO:Declaring metric variables
2023-01-09 18:04:44,968:INFO:Importing untrained model
2023-01-09 18:04:44,968:INFO:K Neighbors Regressor Imported successfully
2023-01-09 18:04:44,969:INFO:Starting cross validation
2023-01-09 18:04:44,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:45,060:INFO:Calculating mean and std
2023-01-09 18:04:45,061:INFO:Creating metrics dataframe
2023-01-09 18:04:45,065:INFO:Uploading results into container
2023-01-09 18:04:45,066:INFO:Uploading model into container now
2023-01-09 18:04:45,067:INFO:_master_model_container: 18
2023-01-09 18:04:45,067:INFO:_display_container: 2
2023-01-09 18:04:45,067:INFO:DummyRegressor()
2023-01-09 18:04:45,067:INFO:create_model() successfully completed......................................
2023-01-09 18:04:45,171:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:45,171:INFO:Creating metrics dataframe
2023-01-09 18:04:45,182:INFO:Initializing create_model()
2023-01-09 18:04:45,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A2662667A0>, estimator=LGBMRegressor(random_state=2540), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:45,183:INFO:Checking exceptions
2023-01-09 18:04:45,184:INFO:Importing libraries
2023-01-09 18:04:45,184:INFO:Copying training dataset
2023-01-09 18:04:45,219:INFO:Defining folds
2023-01-09 18:04:45,219:INFO:Declaring metric variables
2023-01-09 18:04:45,220:INFO:Importing untrained model
2023-01-09 18:04:45,220:INFO:Declaring custom model
2023-01-09 18:04:45,222:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:04:45,223:INFO:Cross validation set to False
2023-01-09 18:04:45,223:INFO:Fitting Model
2023-01-09 18:04:45,414:INFO:Calculating mean and std
2023-01-09 18:04:45,428:INFO:Creating metrics dataframe
2023-01-09 18:04:45,437:INFO:Uploading results into container
2023-01-09 18:04:45,440:INFO:Uploading model into container now
2023-01-09 18:04:45,441:INFO:_master_model_container: 11
2023-01-09 18:04:45,442:INFO:_display_container: 2
2023-01-09 18:04:45,443:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-09 18:04:45,443:INFO:create_model() successfully completed......................................
2023-01-09 18:04:45,600:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:45,601:INFO:Creating metrics dataframe
2023-01-09 18:04:45,608:INFO:Initializing Decision Tree Regressor
2023-01-09 18:04:45,608:INFO:Total runtime is 0.23011272350947065 minutes
2023-01-09 18:04:45,608:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:45,608:INFO:Initializing create_model()
2023-01-09 18:04:45,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:45,618:INFO:Checking exceptions
2023-01-09 18:04:45,618:INFO:Importing libraries
2023-01-09 18:04:45,618:INFO:Copying training dataset
2023-01-09 18:04:45,659:INFO:Defining folds
2023-01-09 18:04:45,660:INFO:Declaring metric variables
2023-01-09 18:04:45,661:INFO:Importing untrained model
2023-01-09 18:04:45,662:INFO:Decision Tree Regressor Imported successfully
2023-01-09 18:04:45,663:INFO:Starting cross validation
2023-01-09 18:04:45,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:04:46,467:INFO:LGBMRegressor(random_state=2540)
2023-01-09 18:04:46,473:INFO:create_model() successfully completed......................................
2023-01-09 18:04:46,656:INFO:Calculating mean and std
2023-01-09 18:04:46,663:INFO:Creating metrics dataframe
2023-01-09 18:04:46,664:INFO:_master_model_container: 18
2023-01-09 18:04:46,669:INFO:Uploading results into container
2023-01-09 18:04:46,669:INFO:_display_container: 2
2023-01-09 18:04:46,670:INFO:Uploading model into container now
2023-01-09 18:04:46,671:INFO:LGBMRegressor(random_state=2540)
2023-01-09 18:04:46,673:INFO:_master_model_container: 12
2023-01-09 18:04:46,675:INFO:compare_models() successfully completed......................................
2023-01-09 18:04:46,676:INFO:_display_container: 2
2023-01-09 18:04:46,678:INFO:DecisionTreeRegressor(random_state=2574)
2023-01-09 18:04:46,678:INFO:create_model() successfully completed......................................
2023-01-09 18:04:46,776:INFO:SubProcess create_model() end ==================================
2023-01-09 18:04:46,776:INFO:Creating metrics dataframe
2023-01-09 18:04:46,792:INFO:Initializing Random Forest Regressor
2023-01-09 18:04:46,792:INFO:Total runtime is 0.24984604914983116 minutes
2023-01-09 18:04:46,793:INFO:SubProcess create_model() called ==================================
2023-01-09 18:04:46,793:INFO:Initializing create_model()
2023-01-09 18:04:46,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:04:46,793:INFO:Checking exceptions
2023-01-09 18:04:46,793:INFO:Importing libraries
2023-01-09 18:04:46,793:INFO:Copying training dataset
2023-01-09 18:04:46,923:INFO:Defining folds
2023-01-09 18:04:46,923:INFO:Declaring metric variables
2023-01-09 18:04:46,923:INFO:Importing untrained model
2023-01-09 18:04:46,924:INFO:Random Forest Regressor Imported successfully
2023-01-09 18:04:46,924:INFO:Starting cross validation
2023-01-09 18:04:46,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:02,556:INFO:Calculating mean and std
2023-01-09 18:05:02,570:INFO:Creating metrics dataframe
2023-01-09 18:05:02,576:INFO:Uploading results into container
2023-01-09 18:05:02,577:INFO:Uploading model into container now
2023-01-09 18:05:02,579:INFO:_master_model_container: 13
2023-01-09 18:05:02,579:INFO:_display_container: 2
2023-01-09 18:05:02,580:INFO:RandomForestRegressor(n_jobs=-1, random_state=2574)
2023-01-09 18:05:02,580:INFO:create_model() successfully completed......................................
2023-01-09 18:05:02,711:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:02,711:INFO:Creating metrics dataframe
2023-01-09 18:05:02,711:INFO:Initializing Extra Trees Regressor
2023-01-09 18:05:02,711:INFO:Total runtime is 0.5151620825131735 minutes
2023-01-09 18:05:02,711:INFO:SubProcess create_model() called ==================================
2023-01-09 18:05:02,711:INFO:Initializing create_model()
2023-01-09 18:05:02,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:02,711:INFO:Checking exceptions
2023-01-09 18:05:02,711:INFO:Importing libraries
2023-01-09 18:05:02,711:INFO:Copying training dataset
2023-01-09 18:05:02,757:INFO:Defining folds
2023-01-09 18:05:02,757:INFO:Declaring metric variables
2023-01-09 18:05:02,757:INFO:Importing untrained model
2023-01-09 18:05:02,761:INFO:Extra Trees Regressor Imported successfully
2023-01-09 18:05:02,761:INFO:Starting cross validation
2023-01-09 18:05:02,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:10,916:INFO:Calculating mean and std
2023-01-09 18:05:10,917:INFO:Creating metrics dataframe
2023-01-09 18:05:10,923:INFO:Uploading results into container
2023-01-09 18:05:10,924:INFO:Uploading model into container now
2023-01-09 18:05:10,925:INFO:_master_model_container: 14
2023-01-09 18:05:10,929:INFO:_display_container: 2
2023-01-09 18:05:10,931:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2574)
2023-01-09 18:05:10,931:INFO:create_model() successfully completed......................................
2023-01-09 18:05:11,088:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:11,088:INFO:Creating metrics dataframe
2023-01-09 18:05:11,102:INFO:Initializing AdaBoost Regressor
2023-01-09 18:05:11,103:INFO:Total runtime is 0.6550251881281536 minutes
2023-01-09 18:05:11,108:INFO:SubProcess create_model() called ==================================
2023-01-09 18:05:11,109:INFO:Initializing create_model()
2023-01-09 18:05:11,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:11,109:INFO:Checking exceptions
2023-01-09 18:05:11,110:INFO:Importing libraries
2023-01-09 18:05:11,110:INFO:Copying training dataset
2023-01-09 18:05:11,127:INFO:Defining folds
2023-01-09 18:05:11,127:INFO:Declaring metric variables
2023-01-09 18:05:11,128:INFO:Importing untrained model
2023-01-09 18:05:11,128:INFO:AdaBoost Regressor Imported successfully
2023-01-09 18:05:11,129:INFO:Starting cross validation
2023-01-09 18:05:11,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:13,262:INFO:Calculating mean and std
2023-01-09 18:05:13,264:INFO:Creating metrics dataframe
2023-01-09 18:05:13,269:INFO:Uploading results into container
2023-01-09 18:05:13,270:INFO:Uploading model into container now
2023-01-09 18:05:13,271:INFO:_master_model_container: 15
2023-01-09 18:05:13,271:INFO:_display_container: 2
2023-01-09 18:05:13,272:INFO:AdaBoostRegressor(random_state=2574)
2023-01-09 18:05:13,272:INFO:create_model() successfully completed......................................
2023-01-09 18:05:13,370:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:13,370:INFO:Creating metrics dataframe
2023-01-09 18:05:13,392:INFO:Initializing Gradient Boosting Regressor
2023-01-09 18:05:13,392:INFO:Total runtime is 0.6931848883628846 minutes
2023-01-09 18:05:13,393:INFO:SubProcess create_model() called ==================================
2023-01-09 18:05:13,393:INFO:Initializing create_model()
2023-01-09 18:05:13,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:13,393:INFO:Checking exceptions
2023-01-09 18:05:13,393:INFO:Importing libraries
2023-01-09 18:05:13,393:INFO:Copying training dataset
2023-01-09 18:05:13,422:INFO:Defining folds
2023-01-09 18:05:13,423:INFO:Declaring metric variables
2023-01-09 18:05:13,423:INFO:Importing untrained model
2023-01-09 18:05:13,423:INFO:Gradient Boosting Regressor Imported successfully
2023-01-09 18:05:13,424:INFO:Starting cross validation
2023-01-09 18:05:13,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:20,167:INFO:Calculating mean and std
2023-01-09 18:05:20,167:INFO:Creating metrics dataframe
2023-01-09 18:05:20,177:INFO:Uploading results into container
2023-01-09 18:05:20,180:INFO:Uploading model into container now
2023-01-09 18:05:20,181:INFO:_master_model_container: 16
2023-01-09 18:05:20,181:INFO:_display_container: 2
2023-01-09 18:05:20,181:INFO:GradientBoostingRegressor(random_state=2574)
2023-01-09 18:05:20,184:INFO:create_model() successfully completed......................................
2023-01-09 18:05:20,302:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:20,302:INFO:Creating metrics dataframe
2023-01-09 18:05:20,302:INFO:Initializing Light Gradient Boosting Machine
2023-01-09 18:05:20,302:INFO:Total runtime is 0.8083456436793011 minutes
2023-01-09 18:05:20,302:INFO:SubProcess create_model() called ==================================
2023-01-09 18:05:20,302:INFO:Initializing create_model()
2023-01-09 18:05:20,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:20,302:INFO:Checking exceptions
2023-01-09 18:05:20,302:INFO:Importing libraries
2023-01-09 18:05:20,302:INFO:Copying training dataset
2023-01-09 18:05:20,334:INFO:Defining folds
2023-01-09 18:05:20,334:INFO:Declaring metric variables
2023-01-09 18:05:20,334:INFO:Importing untrained model
2023-01-09 18:05:20,335:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:05:20,335:INFO:Starting cross validation
2023-01-09 18:05:20,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:21,034:INFO:Calculating mean and std
2023-01-09 18:05:21,034:INFO:Creating metrics dataframe
2023-01-09 18:05:21,042:INFO:Uploading results into container
2023-01-09 18:05:21,043:INFO:Uploading model into container now
2023-01-09 18:05:21,044:INFO:_master_model_container: 17
2023-01-09 18:05:21,044:INFO:_display_container: 2
2023-01-09 18:05:21,044:INFO:LGBMRegressor(random_state=2574)
2023-01-09 18:05:21,044:INFO:create_model() successfully completed......................................
2023-01-09 18:05:21,144:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:21,144:INFO:Creating metrics dataframe
2023-01-09 18:05:21,160:INFO:Initializing Dummy Regressor
2023-01-09 18:05:21,160:INFO:Total runtime is 0.8226445118586223 minutes
2023-01-09 18:05:21,160:INFO:SubProcess create_model() called ==================================
2023-01-09 18:05:21,160:INFO:Initializing create_model()
2023-01-09 18:05:21,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A26A34B880>, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:21,160:INFO:Checking exceptions
2023-01-09 18:05:21,160:INFO:Importing libraries
2023-01-09 18:05:21,160:INFO:Copying training dataset
2023-01-09 18:05:21,185:INFO:Defining folds
2023-01-09 18:05:21,185:INFO:Declaring metric variables
2023-01-09 18:05:21,185:INFO:Importing untrained model
2023-01-09 18:05:21,186:INFO:Dummy Regressor Imported successfully
2023-01-09 18:05:21,186:INFO:Starting cross validation
2023-01-09 18:05:21,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-09 18:05:21,477:INFO:Calculating mean and std
2023-01-09 18:05:21,478:INFO:Creating metrics dataframe
2023-01-09 18:05:21,483:INFO:Uploading results into container
2023-01-09 18:05:21,484:INFO:Uploading model into container now
2023-01-09 18:05:21,484:INFO:_master_model_container: 18
2023-01-09 18:05:21,484:INFO:_display_container: 2
2023-01-09 18:05:21,484:INFO:DummyRegressor()
2023-01-09 18:05:21,484:INFO:create_model() successfully completed......................................
2023-01-09 18:05:21,583:INFO:SubProcess create_model() end ==================================
2023-01-09 18:05:21,583:INFO:Creating metrics dataframe
2023-01-09 18:05:21,604:INFO:Initializing create_model()
2023-01-09 18:05:21,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A26B13F7F0>, estimator=LGBMRegressor(random_state=2574), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-09 18:05:21,605:INFO:Checking exceptions
2023-01-09 18:05:21,606:INFO:Importing libraries
2023-01-09 18:05:21,607:INFO:Copying training dataset
2023-01-09 18:05:21,618:INFO:Defining folds
2023-01-09 18:05:21,618:INFO:Declaring metric variables
2023-01-09 18:05:21,619:INFO:Importing untrained model
2023-01-09 18:05:21,619:INFO:Declaring custom model
2023-01-09 18:05:21,620:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-09 18:05:21,621:INFO:Cross validation set to False
2023-01-09 18:05:21,621:INFO:Fitting Model
2023-01-09 18:05:22,189:INFO:LGBMRegressor(random_state=2574)
2023-01-09 18:05:22,191:INFO:create_model() successfully completed......................................
2023-01-09 18:05:22,382:INFO:                                    Model     MAE     MSE    RMSE      R2   RMSLE    MAPE  TT (Sec)
lightgbm  Light Gradient Boosting Machine  0.3131  0.2211  0.4700  0.8336  0.1424  0.1782     0.070
et                  Extra Trees Regressor  0.3369  0.2627  0.5124  0.8024  0.1516  0.1900     0.815
rf                Random Forest Regressor  0.3419  0.2714  0.5208  0.7960  0.1559  0.1962     1.563
gbr           Gradient Boosting Regressor  0.3688  0.2839  0.5327  0.7866  0.1631  0.2131     0.674
dt                Decision Tree Regressor  0.4697  0.5375  0.7328  0.5962  0.2151  0.2592     0.099
ada                    AdaBoost Regressor  0.6827  0.6632  0.8136  0.5013  0.2755  0.5018     0.213
omp           Orthogonal Matching Pursuit  0.6229  0.6959  0.8339  0.4775  0.2597  0.3859     0.032
lr                      Linear Regression  0.5289  0.7373  0.8090  0.4433  0.2243  0.3218     0.196
ridge                    Ridge Regression  0.5289  0.7375  0.8091  0.4432  0.2243  0.3218     0.035
br                         Bayesian Ridge  0.5289  0.7378  0.8092  0.4429  0.2243  0.3218     0.031
en                            Elastic Net  0.6755  0.7620  0.8727  0.4280  0.2772  0.4531     0.497
lar                Least Angle Regression  0.5501  0.8235  0.8449  0.3776  0.2328  0.3382     0.048
lasso                    Lasso Regression  0.7653  0.9451  0.9719  0.2908  0.3074  0.5203     0.021
knn                 K Neighbors Regressor  0.8397  1.1867  1.0890  0.1089  0.3420  0.5416     0.044
llar         Lasso Least Angle Regression  0.9126  1.3332  1.1543 -0.0005  0.3626  0.6234     0.033
dummy                     Dummy Regressor  0.9126  1.3332  1.1543 -0.0005  0.3626  0.6234     0.029
huber                     Huber Regressor  0.5643  1.5365  1.0234 -0.1654  0.2381  0.3324     0.171
par          Passive Aggressive Regressor  1.1035  4.1773  1.4821 -2.0841  0.3705  0.6902     0.043
2023-01-09 18:05:22,383:INFO:_master_model_container: 18
2023-01-09 18:05:22,383:INFO:_display_container: 2
2023-01-09 18:05:22,384:INFO:LGBMRegressor(random_state=2574)
2023-01-09 18:05:22,384:INFO:compare_models() successfully completed......................................
2023-01-09 18:05:22,399:INFO:Initializing save_model()
2023-01-09 18:05:22,399:INFO:save_model(model=LGBMRegressor(random_state=2574), model_name=best_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-09 18:05:22,399:INFO:Adding model into prep_pipe
2023-01-09 18:05:22,418:INFO:Transformation Pipeline and Model Successfully Saved
2023-01-09 18:05:22,419:INFO:best_model.pkl saved in current working directory
2023-01-09 18:05:22,430:INFO:Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', LGBMRegressor(random_state=2574))])
2023-01-09 18:05:22,431:INFO:save_model() successfully completed......................................
2023-01-09 18:05:25,444:WARNING:Summarize dataset:   0%|                                                                                                                                  | 0/5 [00:00<?, ?it/s]Summarize dataset:   0%|                                                                                                     | 0/14 [00:00<?, ?it/s, Describe variable:HouseAge]Summarize dataset:   7%|######6                                                                                      | 1/14 [00:00<00:07,  1.74it/s, Describe variable:HouseAge]Summarize dataset:   7%|######6                                                                                      | 1/14 [00:00<00:07,  1.74it/s, Describe variable:Latitude]Summarize dataset:  14%|#############1                                                                              | 2/14 [00:00<00:06,  1.74it/s, Describe variable:Longitude]Summarize dataset:  21%|###################5                                                                       | 3/14 [00:00<00:06,  1.74it/s, Describe variable:Population]Summarize dataset:  29%|##########################5                                                                  | 4/14 [00:00<00:05,  1.74it/s, Describe variable:AveOccup]Summarize dataset:  36%|#################################2                                                           | 5/14 [00:00<00:05,  1.74it/s, Describe variable:AveRooms]Summarize dataset:  43%|########################################7                                                      | 6/14 [00:00<00:04,  1.74it/s, Describe variable:MedInc]Summarize dataset:  50%|##############################################                                              | 7/14 [00:00<00:04,  1.74it/s, Describe variable:AveBedrms]Summarize dataset:  57%|###################################################4                                      | 8/14 [00:00<00:03,  1.74it/s, Describe variable:MedHouseVal]Summarize dataset:  64%|#########################################################8                                | 9/14 [00:00<00:00, 16.99it/s, Describe variable:MedHouseVal]Summarize dataset:  64%|################################################################9                                    | 9/14 [00:00<00:00, 16.99it/s, Get variable types]Summarize dataset:  62%|#########################################################5                                  | 10/16 [00:00<00:00, 16.99it/s, Calculate auto correlation]Summarize dataset:  69%|####################################################################7                               | 11/16 [00:01<00:00, 16.99it/s, Get scatter matrix]Summarize dataset:  11%|##########8                                                                                     | 11/97 [00:01<00:05, 16.99it/s, scatter MedInc, MedInc]Summarize dataset:  12%|###########6                                                                                  | 12/97 [00:01<00:05, 16.99it/s, scatter HouseAge, MedInc]Summarize dataset:  13%|############5                                                                                 | 13/97 [00:02<00:04, 16.99it/s, scatter AveRooms, MedInc]Summarize dataset:  14%|#############5                                                                                | 14/97 [00:03<00:21,  3.88it/s, scatter AveRooms, MedInc]Summarize dataset:  14%|#############4                                                                               | 14/97 [00:03<00:21,  3.88it/s, scatter AveBedrms, MedInc]Summarize dataset:  15%|##############2                                                                             | 15/97 [00:03<00:21,  3.88it/s, scatter Population, MedInc]Summarize dataset:  16%|###############5                                                                              | 16/97 [00:04<00:20,  3.88it/s, scatter AveOccup, MedInc]Summarize dataset:  18%|################4                                                                             | 17/97 [00:05<00:28,  2.76it/s, scatter AveOccup, MedInc]Summarize dataset:  18%|################4                                                                             | 17/97 [00:05<00:28,  2.76it/s, scatter Latitude, MedInc]Summarize dataset:  19%|#################2                                                                           | 18/97 [00:05<00:28,  2.76it/s, scatter Longitude, MedInc]Summarize dataset:  20%|##################2                                                                          | 19/97 [00:07<00:39,  1.99it/s, scatter Longitude, MedInc]Summarize dataset:  20%|#################8                                                                         | 19/97 [00:07<00:39,  1.99it/s, scatter MedHouseVal, MedInc]Summarize dataset:  21%|###################3                                                                          | 20/97 [00:07<00:38,  1.99it/s, scatter MedInc, HouseAge]Summarize dataset:  22%|####################3                                                                         | 21/97 [00:08<00:43,  1.75it/s, scatter MedInc, HouseAge]Summarize dataset:  22%|###################9                                                                        | 21/97 [00:08<00:43,  1.75it/s, scatter HouseAge, HouseAge]Summarize dataset:  23%|####################8                                                                       | 22/97 [00:09<00:41,  1.79it/s, scatter HouseAge, HouseAge]Summarize dataset:  23%|####################8                                                                       | 22/97 [00:09<00:41,  1.79it/s, scatter AveRooms, HouseAge]Summarize dataset:  24%|#####################8                                                                      | 23/97 [00:10<00:45,  1.64it/s, scatter AveRooms, HouseAge]Summarize dataset:  24%|#####################5                                                                     | 23/97 [00:10<00:45,  1.64it/s, scatter AveBedrms, HouseAge]Summarize dataset:  25%|######################5                                                                    | 24/97 [00:12<01:14,  1.02s/it, scatter AveBedrms, HouseAge]Summarize dataset:  25%|######################2                                                                   | 24/97 [00:12<01:14,  1.02s/it, scatter Population, HouseAge]Summarize dataset:  26%|#######################1                                                                  | 25/97 [00:15<01:36,  1.35s/it, scatter Population, HouseAge]Summarize dataset:  26%|#######################7                                                                    | 25/97 [00:15<01:36,  1.35s/it, scatter AveOccup, HouseAge]Summarize dataset:  27%|########################6                                                                   | 26/97 [00:18<02:00,  1.70s/it, scatter AveOccup, HouseAge]Summarize dataset:  27%|########################6                                                                   | 26/97 [00:18<02:00,  1.70s/it, scatter Latitude, HouseAge]Summarize dataset:  28%|#########################6                                                                  | 27/97 [00:20<02:05,  1.80s/it, scatter Latitude, HouseAge]Summarize dataset:  28%|#########################3                                                                 | 27/97 [00:20<02:05,  1.80s/it, scatter Longitude, HouseAge]Summarize dataset:  29%|##########################2                                                                | 28/97 [00:21<01:47,  1.55s/it, scatter Longitude, HouseAge]Summarize dataset:  29%|#########################6                                                               | 28/97 [00:21<01:47,  1.55s/it, scatter MedHouseVal, HouseAge]Summarize dataset:  30%|##########################6                                                              | 29/97 [00:21<01:26,  1.28s/it, scatter MedHouseVal, HouseAge]Summarize dataset:  30%|############################1                                                                 | 29/97 [00:21<01:26,  1.28s/it, scatter MedInc, AveRooms]Summarize dataset:  31%|#############################                                                                 | 30/97 [00:22<01:15,  1.13s/it, scatter MedInc, AveRooms]Summarize dataset:  31%|############################4                                                               | 30/97 [00:22<01:15,  1.13s/it, scatter HouseAge, AveRooms]Summarize dataset:  32%|#############################4                                                              | 31/97 [00:23<01:06,  1.00s/it, scatter HouseAge, AveRooms]Summarize dataset:  32%|#############################4                                                              | 31/97 [00:23<01:06,  1.00s/it, scatter AveRooms, AveRooms]Summarize dataset:  33%|##############################3                                                             | 32/97 [00:23<01:00,  1.08it/s, scatter AveRooms, AveRooms]Summarize dataset:  33%|##############################                                                             | 32/97 [00:23<01:00,  1.08it/s, scatter AveBedrms, AveRooms]Summarize dataset:  34%|##############################9                                                            | 33/97 [00:24<00:53,  1.19it/s, scatter AveBedrms, AveRooms]Summarize dataset:  34%|##############################6                                                           | 33/97 [00:24<00:53,  1.19it/s, scatter Population, AveRooms]Summarize dataset:  35%|###############################5                                                          | 34/97 [00:24<00:46,  1.37it/s, scatter Population, AveRooms]Summarize dataset:  35%|################################2                                                           | 34/97 [00:24<00:46,  1.37it/s, scatter AveOccup, AveRooms]Summarize dataset:  36%|#################################1                                                          | 35/97 [00:26<01:00,  1.02it/s, scatter AveOccup, AveRooms]Summarize dataset:  36%|#################################1                                                          | 35/97 [00:26<01:00,  1.02it/s, scatter Latitude, AveRooms]Summarize dataset:  37%|##################################1                                                         | 36/97 [00:28<01:24,  1.38s/it, scatter Latitude, AveRooms]Summarize dataset:  37%|#################################7                                                         | 36/97 [00:28<01:24,  1.38s/it, scatter Longitude, AveRooms]Summarize dataset:  38%|##################################7                                                        | 37/97 [00:30<01:30,  1.50s/it, scatter Longitude, AveRooms]Summarize dataset:  38%|#################################9                                                       | 37/97 [00:30<01:30,  1.50s/it, scatter MedHouseVal, AveRooms]Summarize dataset:  39%|##################################8                                                      | 38/97 [00:31<01:16,  1.29s/it, scatter MedHouseVal, AveRooms]Summarize dataset:  39%|####################################4                                                        | 38/97 [00:31<01:16,  1.29s/it, scatter MedInc, AveBedrms]Summarize dataset:  40%|#####################################3                                                       | 39/97 [00:32<01:05,  1.13s/it, scatter MedInc, AveBedrms]Summarize dataset:  40%|####################################5                                                      | 39/97 [00:32<01:05,  1.13s/it, scatter HouseAge, AveBedrms]Summarize dataset:  41%|#####################################5                                                     | 40/97 [00:32<00:57,  1.01s/it, scatter HouseAge, AveBedrms]Summarize dataset:  41%|#####################################5                                                     | 40/97 [00:32<00:57,  1.01s/it, scatter AveRooms, AveBedrms]Summarize dataset:  42%|######################################4                                                    | 41/97 [00:33<00:49,  1.14it/s, scatter AveRooms, AveBedrms]Summarize dataset:  42%|######################################                                                    | 41/97 [00:33<00:49,  1.14it/s, scatter AveBedrms, AveBedrms]Summarize dataset:  43%|######################################9                                                   | 42/97 [00:34<00:43,  1.27it/s, scatter AveBedrms, AveBedrms]Summarize dataset:  43%|######################################5                                                  | 42/97 [00:34<00:43,  1.27it/s, scatter Population, AveBedrms]Summarize dataset:  44%|#######################################4                                                 | 43/97 [00:34<00:35,  1.54it/s, scatter Population, AveBedrms]Summarize dataset:  44%|########################################3                                                  | 43/97 [00:34<00:35,  1.54it/s, scatter AveOccup, AveBedrms]Summarize dataset:  45%|#########################################2                                                 | 44/97 [00:34<00:28,  1.86it/s, scatter AveOccup, AveBedrms]Summarize dataset:  45%|#########################################2                                                 | 44/97 [00:34<00:28,  1.86it/s, scatter Latitude, AveBedrms]Summarize dataset:  46%|##########################################2                                                | 45/97 [00:34<00:22,  2.28it/s, scatter Latitude, AveBedrms]Summarize dataset:  46%|#########################################7                                                | 45/97 [00:34<00:22,  2.28it/s, scatter Longitude, AveBedrms]Summarize dataset:  47%|##########################################6                                               | 46/97 [00:35<00:22,  2.27it/s, scatter Longitude, AveBedrms]Summarize dataset:  47%|#########################################7                                              | 46/97 [00:35<00:22,  2.27it/s, scatter MedHouseVal, AveBedrms]Summarize dataset:  48%|##########################################6                                             | 47/97 [00:35<00:22,  2.25it/s, scatter MedHouseVal, AveBedrms]Summarize dataset:  48%|############################################5                                               | 47/97 [00:35<00:22,  2.25it/s, scatter MedInc, Population]Summarize dataset:  49%|#############################################5                                              | 48/97 [00:36<00:20,  2.34it/s, scatter MedInc, Population]Summarize dataset:  49%|############################################5                                             | 48/97 [00:36<00:20,  2.34it/s, scatter HouseAge, Population]Summarize dataset:  51%|#############################################4                                            | 49/97 [00:36<00:18,  2.53it/s, scatter HouseAge, Population]Summarize dataset:  51%|#############################################4                                            | 49/97 [00:36<00:18,  2.53it/s, scatter AveRooms, Population]Summarize dataset:  52%|##############################################3                                           | 50/97 [00:36<00:18,  2.55it/s, scatter AveRooms, Population]Summarize dataset:  52%|#############################################8                                           | 50/97 [00:36<00:18,  2.55it/s, scatter AveBedrms, Population]Summarize dataset:  53%|##############################################7                                          | 51/97 [00:37<00:18,  2.53it/s, scatter AveBedrms, Population]Summarize dataset:  53%|##############################################2                                         | 51/97 [00:37<00:18,  2.53it/s, scatter Population, Population]Summarize dataset:  54%|###############################################1                                        | 52/97 [00:37<00:17,  2.59it/s, scatter Population, Population]Summarize dataset:  54%|################################################2                                         | 52/97 [00:37<00:17,  2.59it/s, scatter AveOccup, Population]Summarize dataset:  55%|#################################################1                                        | 53/97 [00:38<00:17,  2.55it/s, scatter AveOccup, Population]Summarize dataset:  55%|#################################################1                                        | 53/97 [00:38<00:17,  2.55it/s, scatter Latitude, Population]Summarize dataset:  56%|##################################################1                                       | 54/97 [00:38<00:16,  2.67it/s, scatter Latitude, Population]Summarize dataset:  56%|#################################################5                                       | 54/97 [00:38<00:16,  2.67it/s, scatter Longitude, Population]Summarize dataset:  57%|##################################################4                                      | 55/97 [00:38<00:15,  2.67it/s, scatter Longitude, Population]Summarize dataset:  57%|#################################################3                                     | 55/97 [00:38<00:15,  2.67it/s, scatter MedHouseVal, Population]Summarize dataset:  58%|##################################################2                                    | 56/97 [00:39<00:14,  2.74it/s, scatter MedHouseVal, Population]Summarize dataset:  58%|######################################################2                                       | 56/97 [00:39<00:14,  2.74it/s, scatter MedInc, AveOccup]Summarize dataset:  59%|#######################################################2                                      | 57/97 [00:39<00:13,  2.91it/s, scatter MedInc, AveOccup]Summarize dataset:  59%|######################################################                                      | 57/97 [00:39<00:13,  2.91it/s, scatter HouseAge, AveOccup]Summarize dataset:  60%|#######################################################                                     | 58/97 [00:39<00:12,  3.08it/s, scatter HouseAge, AveOccup]Summarize dataset:  60%|#######################################################                                     | 58/97 [00:39<00:12,  3.08it/s, scatter AveRooms, AveOccup]Summarize dataset:  61%|#######################################################9                                    | 59/97 [00:39<00:11,  3.21it/s, scatter AveRooms, AveOccup]Summarize dataset:  61%|#######################################################3                                   | 59/97 [00:39<00:11,  3.21it/s, scatter AveBedrms, AveOccup]Summarize dataset:  62%|########################################################2                                  | 60/97 [00:40<00:10,  3.55it/s, scatter AveBedrms, AveOccup]Summarize dataset:  62%|#######################################################6                                  | 60/97 [00:40<00:10,  3.55it/s, scatter Population, AveOccup]Summarize dataset:  63%|########################################################5                                 | 61/97 [00:40<00:09,  3.71it/s, scatter Population, AveOccup]Summarize dataset:  63%|#########################################################8                                  | 61/97 [00:40<00:09,  3.71it/s, scatter AveOccup, AveOccup]Summarize dataset:  64%|##########################################################8                                 | 62/97 [00:40<00:09,  3.72it/s, scatter AveOccup, AveOccup]Summarize dataset:  64%|##########################################################8                                 | 62/97 [00:40<00:09,  3.72it/s, scatter Latitude, AveOccup]Summarize dataset:  65%|###########################################################7                                | 63/97 [00:40<00:08,  3.83it/s, scatter Latitude, AveOccup]Summarize dataset:  65%|###########################################################1                               | 63/97 [00:40<00:08,  3.83it/s, scatter Longitude, AveOccup]Summarize dataset:  66%|############################################################                               | 64/97 [00:41<00:07,  4.14it/s, scatter Longitude, AveOccup]Summarize dataset:  66%|##########################################################7                              | 64/97 [00:41<00:07,  4.14it/s, scatter MedHouseVal, AveOccup]Summarize dataset:  67%|###########################################################6                             | 65/97 [00:41<00:07,  4.47it/s, scatter MedHouseVal, AveOccup]Summarize dataset:  67%|##############################################################9                               | 65/97 [00:41<00:07,  4.47it/s, scatter MedInc, Latitude]Summarize dataset:  68%|###############################################################9                              | 66/97 [00:41<00:06,  4.76it/s, scatter MedInc, Latitude]Summarize dataset:  68%|##############################################################5                             | 66/97 [00:41<00:06,  4.76it/s, scatter HouseAge, Latitude]Summarize dataset:  69%|###############################################################5                            | 67/97 [00:41<00:05,  5.07it/s, scatter HouseAge, Latitude]Summarize dataset:  69%|###############################################################5                            | 67/97 [00:41<00:05,  5.07it/s, scatter AveRooms, Latitude]Summarize dataset:  70%|################################################################4                           | 68/97 [00:41<00:05,  5.27it/s, scatter AveRooms, Latitude]Summarize dataset:  70%|###############################################################7                           | 68/97 [00:41<00:05,  5.27it/s, scatter AveBedrms, Latitude]Summarize dataset:  71%|################################################################7                          | 69/97 [00:42<00:06,  4.17it/s, scatter AveBedrms, Latitude]Summarize dataset:  71%|################################################################                          | 69/97 [00:42<00:06,  4.17it/s, scatter Population, Latitude]Summarize dataset:  72%|################################################################9                         | 70/97 [00:42<00:07,  3.57it/s, scatter Population, Latitude]Summarize dataset:  72%|##################################################################3                         | 70/97 [00:42<00:07,  3.57it/s, scatter AveOccup, Latitude]Summarize dataset:  73%|###################################################################3                        | 71/97 [00:42<00:06,  3.79it/s, scatter AveOccup, Latitude]Summarize dataset:  73%|###################################################################3                        | 71/97 [00:42<00:06,  3.79it/s, scatter Latitude, Latitude]Summarize dataset:  74%|####################################################################2                       | 72/97 [00:43<00:07,  3.37it/s, scatter Latitude, Latitude]Summarize dataset:  74%|###################################################################5                       | 72/97 [00:43<00:07,  3.37it/s, scatter Longitude, Latitude]Summarize dataset:  75%|####################################################################4                      | 73/97 [00:43<00:07,  3.29it/s, scatter Longitude, Latitude]Summarize dataset:  75%|##################################################################9                      | 73/97 [00:43<00:07,  3.29it/s, scatter MedHouseVal, Latitude]Summarize dataset:  76%|###################################################################8                     | 74/97 [00:43<00:06,  3.55it/s, scatter MedHouseVal, Latitude]Summarize dataset:  76%|######################################################################9                      | 74/97 [00:43<00:06,  3.55it/s, scatter MedInc, Longitude]Summarize dataset:  77%|#######################################################################9                     | 75/97 [00:44<00:09,  2.34it/s, scatter MedInc, Longitude]Summarize dataset:  77%|######################################################################3                    | 75/97 [00:44<00:09,  2.34it/s, scatter HouseAge, Longitude]Summarize dataset:  78%|#######################################################################2                   | 76/97 [00:44<00:07,  2.87it/s, scatter HouseAge, Longitude]Summarize dataset:  78%|#######################################################################2                   | 76/97 [00:44<00:07,  2.87it/s, scatter AveRooms, Longitude]Summarize dataset:  79%|########################################################################2                  | 77/97 [00:44<00:05,  3.46it/s, scatter AveRooms, Longitude]Summarize dataset:  79%|#######################################################################4                  | 77/97 [00:44<00:05,  3.46it/s, scatter AveBedrms, Longitude]Summarize dataset:  80%|########################################################################3                 | 78/97 [00:44<00:04,  4.09it/s, scatter AveBedrms, Longitude]Summarize dataset:  80%|#######################################################################5                 | 78/97 [00:44<00:04,  4.09it/s, scatter Population, Longitude]Summarize dataset:  81%|########################################################################4                | 79/97 [00:45<00:03,  4.74it/s, scatter Population, Longitude]Summarize dataset:  81%|##########################################################################1                | 79/97 [00:45<00:03,  4.74it/s, scatter AveOccup, Longitude]Summarize dataset:  82%|###########################################################################                | 80/97 [00:45<00:03,  5.35it/s, scatter AveOccup, Longitude]Summarize dataset:  82%|###########################################################################                | 80/97 [00:45<00:03,  5.35it/s, scatter Latitude, Longitude]Summarize dataset:  84%|###########################################################################9               | 81/97 [00:45<00:02,  6.04it/s, scatter Latitude, Longitude]Summarize dataset:  84%|###########################################################################1              | 81/97 [00:45<00:02,  6.04it/s, scatter Longitude, Longitude]Summarize dataset:  85%|############################################################################              | 82/97 [00:45<00:02,  6.36it/s, scatter Longitude, Longitude]Summarize dataset:  85%|##########################################################################3             | 82/97 [00:45<00:02,  6.36it/s, scatter MedHouseVal, Longitude]Summarize dataset:  86%|###########################################################################2            | 83/97 [00:45<00:02,  6.69it/s, scatter MedHouseVal, Longitude]Summarize dataset:  86%|#############################################################################8             | 83/97 [00:45<00:02,  6.69it/s, scatter MedInc, MedHouseVal]Summarize dataset:  87%|##############################################################################8            | 84/97 [00:45<00:01,  6.94it/s, scatter MedInc, MedHouseVal]Summarize dataset:  87%|#############################################################################            | 84/97 [00:45<00:01,  6.94it/s, scatter HouseAge, MedHouseVal]Summarize dataset:  88%|#############################################################################9           | 85/97 [00:45<00:01,  7.03it/s, scatter HouseAge, MedHouseVal]Summarize dataset:  88%|#############################################################################9           | 85/97 [00:45<00:01,  7.03it/s, scatter AveRooms, MedHouseVal]Summarize dataset:  89%|##############################################################################9          | 86/97 [00:45<00:01,  7.17it/s, scatter AveRooms, MedHouseVal]Summarize dataset:  89%|##############################################################################          | 86/97 [00:45<00:01,  7.17it/s, scatter AveBedrms, MedHouseVal]Summarize dataset:  90%|##############################################################################9         | 87/97 [00:46<00:01,  7.31it/s, scatter AveBedrms, MedHouseVal]Summarize dataset:  90%|##############################################################################         | 87/97 [00:46<00:01,  7.31it/s, scatter Population, MedHouseVal]Summarize dataset:  91%|##############################################################################9        | 88/97 [00:46<00:01,  7.29it/s, scatter Population, MedHouseVal]Summarize dataset:  91%|################################################################################7        | 88/97 [00:46<00:01,  7.29it/s, scatter AveOccup, MedHouseVal]Summarize dataset:  92%|#################################################################################6       | 89/97 [00:46<00:01,  7.39it/s, scatter AveOccup, MedHouseVal]Summarize dataset:  92%|#################################################################################6       | 89/97 [00:46<00:01,  7.39it/s, scatter Latitude, MedHouseVal]Summarize dataset:  93%|##################################################################################5      | 90/97 [00:46<00:00,  7.54it/s, scatter Latitude, MedHouseVal]Summarize dataset:  93%|#################################################################################6      | 90/97 [00:46<00:00,  7.54it/s, scatter Longitude, MedHouseVal]Summarize dataset:  94%|##################################################################################5     | 91/97 [00:46<00:00,  7.38it/s, scatter Longitude, MedHouseVal]Summarize dataset:  94%|################################################################################6     | 91/97 [00:46<00:00,  7.38it/s, scatter MedHouseVal, MedHouseVal]Summarize dataset:  95%|#################################################################################5    | 92/97 [00:46<00:00,  6.96it/s, scatter MedHouseVal, MedHouseVal]Summarize dataset:  95%|#########################################################################################1    | 92/97 [00:46<00:00,  6.96it/s, Get dataframe statistics]Summarize dataset:  94%|#############################################################################################      | 93/99 [00:46<00:00,  6.96it/s, Missing diagram bar]Summarize dataset:  95%|##############################################################################################     | 94/99 [00:47<00:00,  7.14it/s, Missing diagram bar]Summarize dataset:  95%|###########################################################################################1    | 94/99 [00:47<00:00,  7.14it/s, Missing diagram matrix]Summarize dataset:  96%|############################################################################################1   | 95/99 [00:47<00:00,  7.34it/s, Missing diagram matrix]Summarize dataset:  96%|######################################################################################################6    | 95/99 [00:47<00:00,  7.34it/s, Take sample]Summarize dataset:  97%|###############################################################################################   | 96/99 [00:47<00:00,  7.34it/s, Detecting duplicates]Summarize dataset:  98%|#########################################################################################################8  | 97/99 [00:47<00:00,  7.34it/s, Get alerts]Summarize dataset:  99%|############################################################################################# | 98/99 [00:47<00:00,  7.34it/s, Get reproduction details]Summarize dataset: 100%|#############################################################################################################| 99/99 [00:47<00:00,  7.34it/s, Completed]Summarize dataset: 100%|#############################################################################################################| 99/99 [00:47<00:00,  2.10it/s, Completed]
2023-01-09 18:05:28,881:WARNING:Generate report structure:   0%|                                                                                                                          | 0/1 [00:00<?, ?it/s]Generate report structure: 100%|##################################################################################################################| 1/1 [00:03<00:00,  3.43s/it]Generate report structure: 100%|##################################################################################################################| 1/1 [00:03<00:00,  3.43s/it]
2023-01-09 18:05:32,080:WARNING:Render HTML:   0%|                                                                                                                                        | 0/1 [00:00<?, ?it/s]Render HTML: 100%|################################################################################################################################| 1/1 [00:03<00:00,  3.20s/it]Render HTML: 100%|################################################################################################################################| 1/1 [00:03<00:00,  3.20s/it]
2023-01-09 18:09:06,917:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-09 18:09:21,231:WARNING:Summarize dataset:   0%|                                                                                                                                  | 0/5 [00:00<?, ?it/s]Summarize dataset:   0%|                                                                                                     | 0/14 [00:00<?, ?it/s, Describe variable:HouseAge]Summarize dataset:   7%|######5                                                                                     | 1/14 [00:00<00:01,  8.40it/s, Describe variable:Longitude]Summarize dataset:  14%|#############1                                                                              | 2/14 [00:00<00:00, 16.81it/s, Describe variable:Longitude]Summarize dataset:  14%|#############2                                                                               | 2/14 [00:00<00:00, 16.81it/s, Describe variable:Latitude]Summarize dataset:  21%|###################5                                                                       | 3/14 [00:00<00:00, 16.81it/s, Describe variable:Population]Summarize dataset:  29%|##########################5                                                                  | 4/14 [00:00<00:00, 16.81it/s, Describe variable:AveRooms]Summarize dataset:  36%|#################################9                                                             | 5/14 [00:00<00:00, 16.81it/s, Describe variable:MedInc]Summarize dataset:  43%|#######################################4                                                    | 6/14 [00:00<00:00, 16.81it/s, Describe variable:AveBedrms]Summarize dataset:  50%|##############################################5                                              | 7/14 [00:00<00:00, 16.81it/s, Describe variable:AveOccup]Summarize dataset:  57%|###################################################4                                      | 8/14 [00:00<00:00, 16.81it/s, Describe variable:MedHouseVal]Summarize dataset:  64%|################################################################9                                    | 9/14 [00:00<00:00, 16.81it/s, Get variable types]Summarize dataset:  62%|#########################################################5                                  | 10/16 [00:00<00:00, 16.81it/s, Calculate auto correlation]Summarize dataset:  69%|###############################################################2                            | 11/16 [00:00<00:00, 31.39it/s, Calculate auto correlation]Summarize dataset:  69%|####################################################################7                               | 11/16 [00:00<00:00, 31.39it/s, Get scatter matrix]Summarize dataset:  11%|##########8                                                                                     | 11/97 [00:00<00:02, 31.39it/s, scatter MedInc, MedInc]Summarize dataset:  12%|###########6                                                                                  | 12/97 [00:00<00:02, 31.39it/s, scatter HouseAge, MedInc]Summarize dataset:  13%|############5                                                                                 | 13/97 [00:00<00:02, 31.39it/s, scatter AveRooms, MedInc]Summarize dataset:  14%|#############5                                                                                | 14/97 [00:01<00:08, 10.14it/s, scatter AveRooms, MedInc]Summarize dataset:  14%|#############4                                                                               | 14/97 [00:01<00:08, 10.14it/s, scatter AveBedrms, MedInc]Summarize dataset:  15%|##############2                                                                             | 15/97 [00:01<00:08, 10.14it/s, scatter Population, MedInc]Summarize dataset:  16%|###############1                                                                            | 16/97 [00:01<00:10,  7.51it/s, scatter Population, MedInc]Summarize dataset:  16%|###############5                                                                              | 16/97 [00:01<00:10,  7.51it/s, scatter AveOccup, MedInc]Summarize dataset:  18%|################4                                                                             | 17/97 [00:01<00:10,  7.51it/s, scatter Latitude, MedInc]Summarize dataset:  19%|#################4                                                                            | 18/97 [00:02<00:12,  6.56it/s, scatter Latitude, MedInc]Summarize dataset:  19%|#################2                                                                           | 18/97 [00:02<00:12,  6.56it/s, scatter Longitude, MedInc]Summarize dataset:  20%|##################2                                                                          | 19/97 [00:02<00:12,  6.13it/s, scatter Longitude, MedInc]Summarize dataset:  20%|#################8                                                                         | 19/97 [00:02<00:12,  6.13it/s, scatter MedHouseVal, MedInc]Summarize dataset:  21%|##################7                                                                        | 20/97 [00:02<00:14,  5.42it/s, scatter MedHouseVal, MedInc]Summarize dataset:  21%|###################3                                                                          | 20/97 [00:02<00:14,  5.42it/s, scatter MedInc, HouseAge]Summarize dataset:  22%|####################3                                                                         | 21/97 [00:02<00:15,  4.85it/s, scatter MedInc, HouseAge]Summarize dataset:  22%|###################9                                                                        | 21/97 [00:02<00:15,  4.85it/s, scatter HouseAge, HouseAge]Summarize dataset:  23%|####################8                                                                       | 22/97 [00:03<00:16,  4.65it/s, scatter HouseAge, HouseAge]Summarize dataset:  23%|####################8                                                                       | 22/97 [00:03<00:16,  4.65it/s, scatter AveRooms, HouseAge]Summarize dataset:  24%|#####################8                                                                      | 23/97 [00:03<00:16,  4.52it/s, scatter AveRooms, HouseAge]Summarize dataset:  24%|#####################5                                                                     | 23/97 [00:03<00:16,  4.52it/s, scatter AveBedrms, HouseAge]Summarize dataset:  25%|######################5                                                                    | 24/97 [00:03<00:16,  4.35it/s, scatter AveBedrms, HouseAge]Summarize dataset:  25%|######################2                                                                   | 24/97 [00:03<00:16,  4.35it/s, scatter Population, HouseAge]Summarize dataset:  26%|#######################1                                                                  | 25/97 [00:03<00:16,  4.42it/s, scatter Population, HouseAge]Summarize dataset:  26%|#######################7                                                                    | 25/97 [00:03<00:16,  4.42it/s, scatter AveOccup, HouseAge]Summarize dataset:  27%|########################6                                                                   | 26/97 [00:04<00:16,  4.36it/s, scatter AveOccup, HouseAge]Summarize dataset:  27%|########################6                                                                   | 26/97 [00:04<00:16,  4.36it/s, scatter Latitude, HouseAge]Summarize dataset:  28%|#########################6                                                                  | 27/97 [00:04<00:16,  4.19it/s, scatter Latitude, HouseAge]Summarize dataset:  28%|#########################3                                                                 | 27/97 [00:04<00:16,  4.19it/s, scatter Longitude, HouseAge]Summarize dataset:  29%|##########################2                                                                | 28/97 [00:04<00:15,  4.32it/s, scatter Longitude, HouseAge]Summarize dataset:  29%|#########################6                                                               | 28/97 [00:04<00:15,  4.32it/s, scatter MedHouseVal, HouseAge]Summarize dataset:  30%|##########################6                                                              | 29/97 [00:04<00:15,  4.44it/s, scatter MedHouseVal, HouseAge]Summarize dataset:  30%|############################1                                                                 | 29/97 [00:04<00:15,  4.44it/s, scatter MedInc, AveRooms]Summarize dataset:  31%|#############################                                                                 | 30/97 [00:05<00:16,  4.13it/s, scatter MedInc, AveRooms]Summarize dataset:  31%|############################4                                                               | 30/97 [00:05<00:16,  4.13it/s, scatter HouseAge, AveRooms]Summarize dataset:  32%|#############################4                                                              | 31/97 [00:05<00:15,  4.25it/s, scatter HouseAge, AveRooms]Summarize dataset:  32%|#############################4                                                              | 31/97 [00:05<00:15,  4.25it/s, scatter AveRooms, AveRooms]Summarize dataset:  33%|##############################3                                                             | 32/97 [00:05<00:15,  4.12it/s, scatter AveRooms, AveRooms]Summarize dataset:  33%|##############################                                                             | 32/97 [00:05<00:15,  4.12it/s, scatter AveBedrms, AveRooms]Summarize dataset:  34%|##############################9                                                            | 33/97 [00:05<00:14,  4.27it/s, scatter AveBedrms, AveRooms]Summarize dataset:  34%|##############################6                                                           | 33/97 [00:05<00:14,  4.27it/s, scatter Population, AveRooms]Summarize dataset:  35%|###############################5                                                          | 34/97 [00:05<00:13,  4.80it/s, scatter Population, AveRooms]Summarize dataset:  35%|################################2                                                           | 34/97 [00:05<00:13,  4.80it/s, scatter AveOccup, AveRooms]Summarize dataset:  36%|#################################1                                                          | 35/97 [00:06<00:11,  5.18it/s, scatter AveOccup, AveRooms]Summarize dataset:  36%|#################################1                                                          | 35/97 [00:06<00:11,  5.18it/s, scatter Latitude, AveRooms]Summarize dataset:  37%|##################################1                                                         | 36/97 [00:06<00:11,  5.30it/s, scatter Latitude, AveRooms]Summarize dataset:  37%|#################################7                                                         | 36/97 [00:06<00:11,  5.30it/s, scatter Longitude, AveRooms]Summarize dataset:  38%|##################################7                                                        | 37/97 [00:06<00:10,  5.63it/s, scatter Longitude, AveRooms]Summarize dataset:  38%|#################################9                                                       | 37/97 [00:06<00:10,  5.63it/s, scatter MedHouseVal, AveRooms]Summarize dataset:  39%|##################################8                                                      | 38/97 [00:06<00:10,  5.64it/s, scatter MedHouseVal, AveRooms]Summarize dataset:  39%|####################################4                                                        | 38/97 [00:06<00:10,  5.64it/s, scatter MedInc, AveBedrms]Summarize dataset:  40%|#####################################3                                                       | 39/97 [00:06<00:10,  5.41it/s, scatter MedInc, AveBedrms]Summarize dataset:  40%|####################################5                                                      | 39/97 [00:06<00:10,  5.41it/s, scatter HouseAge, AveBedrms]Summarize dataset:  41%|#####################################5                                                     | 40/97 [00:06<00:10,  5.67it/s, scatter HouseAge, AveBedrms]Summarize dataset:  41%|#####################################5                                                     | 40/97 [00:06<00:10,  5.67it/s, scatter AveRooms, AveBedrms]Summarize dataset:  42%|######################################4                                                    | 41/97 [00:07<00:09,  6.03it/s, scatter AveRooms, AveBedrms]Summarize dataset:  42%|######################################                                                    | 41/97 [00:07<00:09,  6.03it/s, scatter AveBedrms, AveBedrms]Summarize dataset:  43%|######################################9                                                   | 42/97 [00:07<00:08,  6.25it/s, scatter AveBedrms, AveBedrms]Summarize dataset:  43%|######################################5                                                  | 42/97 [00:07<00:08,  6.25it/s, scatter Population, AveBedrms]Summarize dataset:  44%|#######################################4                                                 | 43/97 [00:07<00:08,  6.32it/s, scatter Population, AveBedrms]Summarize dataset:  44%|########################################3                                                  | 43/97 [00:07<00:08,  6.32it/s, scatter AveOccup, AveBedrms]Summarize dataset:  45%|#########################################2                                                 | 44/97 [00:07<00:07,  6.66it/s, scatter AveOccup, AveBedrms]Summarize dataset:  45%|#########################################2                                                 | 44/97 [00:07<00:07,  6.66it/s, scatter Latitude, AveBedrms]Summarize dataset:  46%|##########################################2                                                | 45/97 [00:07<00:07,  6.91it/s, scatter Latitude, AveBedrms]Summarize dataset:  46%|#########################################7                                                | 45/97 [00:07<00:07,  6.91it/s, scatter Longitude, AveBedrms]Summarize dataset:  47%|##########################################6                                               | 46/97 [00:07<00:07,  7.01it/s, scatter Longitude, AveBedrms]Summarize dataset:  47%|#########################################7                                              | 46/97 [00:07<00:07,  7.01it/s, scatter MedHouseVal, AveBedrms]Summarize dataset:  48%|##########################################6                                             | 47/97 [00:07<00:07,  6.93it/s, scatter MedHouseVal, AveBedrms]Summarize dataset:  48%|############################################5                                               | 47/97 [00:07<00:07,  6.93it/s, scatter MedInc, Population]Summarize dataset:  49%|#############################################5                                              | 48/97 [00:08<00:06,  7.04it/s, scatter MedInc, Population]Summarize dataset:  49%|############################################5                                             | 48/97 [00:08<00:06,  7.04it/s, scatter HouseAge, Population]Summarize dataset:  51%|#############################################4                                            | 49/97 [00:08<00:06,  7.20it/s, scatter HouseAge, Population]Summarize dataset:  51%|#############################################4                                            | 49/97 [00:08<00:06,  7.20it/s, scatter AveRooms, Population]Summarize dataset:  52%|##############################################3                                           | 50/97 [00:08<00:06,  7.07it/s, scatter AveRooms, Population]Summarize dataset:  52%|#############################################8                                           | 50/97 [00:08<00:06,  7.07it/s, scatter AveBedrms, Population]Summarize dataset:  53%|##############################################7                                          | 51/97 [00:08<00:06,  7.13it/s, scatter AveBedrms, Population]Summarize dataset:  53%|##############################################2                                         | 51/97 [00:08<00:06,  7.13it/s, scatter Population, Population]Summarize dataset:  54%|###############################################1                                        | 52/97 [00:08<00:06,  7.26it/s, scatter Population, Population]Summarize dataset:  54%|################################################2                                         | 52/97 [00:08<00:06,  7.26it/s, scatter AveOccup, Population]Summarize dataset:  55%|#################################################1                                        | 53/97 [00:08<00:05,  7.34it/s, scatter AveOccup, Population]Summarize dataset:  55%|#################################################1                                        | 53/97 [00:08<00:05,  7.34it/s, scatter Latitude, Population]Summarize dataset:  56%|##################################################1                                       | 54/97 [00:08<00:05,  7.33it/s, scatter Latitude, Population]Summarize dataset:  56%|#################################################5                                       | 54/97 [00:08<00:05,  7.33it/s, scatter Longitude, Population]Summarize dataset:  57%|##################################################4                                      | 55/97 [00:09<00:05,  7.41it/s, scatter Longitude, Population]Summarize dataset:  57%|#################################################3                                     | 55/97 [00:09<00:05,  7.41it/s, scatter MedHouseVal, Population]Summarize dataset:  58%|##################################################2                                    | 56/97 [00:09<00:05,  7.42it/s, scatter MedHouseVal, Population]Summarize dataset:  58%|######################################################2                                       | 56/97 [00:09<00:05,  7.42it/s, scatter MedInc, AveOccup]Summarize dataset:  59%|#######################################################2                                      | 57/97 [00:09<00:05,  7.15it/s, scatter MedInc, AveOccup]Summarize dataset:  59%|######################################################                                      | 57/97 [00:09<00:05,  7.15it/s, scatter HouseAge, AveOccup]Summarize dataset:  60%|#######################################################                                     | 58/97 [00:09<00:05,  7.30it/s, scatter HouseAge, AveOccup]Summarize dataset:  60%|#######################################################                                     | 58/97 [00:09<00:05,  7.30it/s, scatter AveRooms, AveOccup]Summarize dataset:  61%|#######################################################9                                    | 59/97 [00:09<00:05,  7.29it/s, scatter AveRooms, AveOccup]Summarize dataset:  61%|#######################################################3                                   | 59/97 [00:09<00:05,  7.29it/s, scatter AveBedrms, AveOccup]Summarize dataset:  62%|########################################################2                                  | 60/97 [00:09<00:06,  5.51it/s, scatter AveBedrms, AveOccup]Summarize dataset:  62%|#######################################################6                                  | 60/97 [00:09<00:06,  5.51it/s, scatter Population, AveOccup]Summarize dataset:  63%|########################################################5                                 | 61/97 [00:09<00:05,  6.01it/s, scatter Population, AveOccup]Summarize dataset:  63%|#########################################################8                                  | 61/97 [00:09<00:05,  6.01it/s, scatter AveOccup, AveOccup]Summarize dataset:  64%|##########################################################8                                 | 62/97 [00:10<00:05,  6.36it/s, scatter AveOccup, AveOccup]Summarize dataset:  64%|##########################################################8                                 | 62/97 [00:10<00:05,  6.36it/s, scatter Latitude, AveOccup]Summarize dataset:  65%|###########################################################7                                | 63/97 [00:10<00:05,  6.70it/s, scatter Latitude, AveOccup]Summarize dataset:  65%|###########################################################1                               | 63/97 [00:10<00:05,  6.70it/s, scatter Longitude, AveOccup]Summarize dataset:  66%|############################################################                               | 64/97 [00:10<00:04,  6.88it/s, scatter Longitude, AveOccup]Summarize dataset:  66%|##########################################################7                              | 64/97 [00:10<00:04,  6.88it/s, scatter MedHouseVal, AveOccup]Summarize dataset:  67%|###########################################################6                             | 65/97 [00:10<00:04,  7.08it/s, scatter MedHouseVal, AveOccup]Summarize dataset:  67%|##############################################################9                               | 65/97 [00:10<00:04,  7.08it/s, scatter MedInc, Latitude]Summarize dataset:  68%|###############################################################9                              | 66/97 [00:10<00:04,  7.10it/s, scatter MedInc, Latitude]Summarize dataset:  68%|##############################################################5                             | 66/97 [00:10<00:04,  7.10it/s, scatter HouseAge, Latitude]Summarize dataset:  69%|###############################################################5                            | 67/97 [00:10<00:03,  7.53it/s, scatter HouseAge, Latitude]Summarize dataset:  69%|###############################################################5                            | 67/97 [00:10<00:03,  7.53it/s, scatter AveRooms, Latitude]Summarize dataset:  70%|################################################################4                           | 68/97 [00:10<00:03,  7.43it/s, scatter AveRooms, Latitude]Summarize dataset:  70%|###############################################################7                           | 68/97 [00:10<00:03,  7.43it/s, scatter AveBedrms, Latitude]Summarize dataset:  71%|################################################################7                          | 69/97 [00:11<00:03,  7.35it/s, scatter AveBedrms, Latitude]Summarize dataset:  71%|################################################################                          | 69/97 [00:11<00:03,  7.35it/s, scatter Population, Latitude]Summarize dataset:  72%|################################################################9                         | 70/97 [00:11<00:03,  7.58it/s, scatter Population, Latitude]Summarize dataset:  72%|##################################################################3                         | 70/97 [00:11<00:03,  7.58it/s, scatter AveOccup, Latitude]Summarize dataset:  73%|###################################################################3                        | 71/97 [00:11<00:03,  7.59it/s, scatter AveOccup, Latitude]Summarize dataset:  73%|###################################################################3                        | 71/97 [00:11<00:03,  7.59it/s, scatter Latitude, Latitude]Summarize dataset:  74%|####################################################################2                       | 72/97 [00:11<00:03,  7.71it/s, scatter Latitude, Latitude]Summarize dataset:  74%|###################################################################5                       | 72/97 [00:11<00:03,  7.71it/s, scatter Longitude, Latitude]Summarize dataset:  75%|####################################################################4                      | 73/97 [00:11<00:03,  7.83it/s, scatter Longitude, Latitude]Summarize dataset:  75%|##################################################################9                      | 73/97 [00:11<00:03,  7.83it/s, scatter MedHouseVal, Latitude]Summarize dataset:  76%|###################################################################8                     | 74/97 [00:11<00:03,  7.60it/s, scatter MedHouseVal, Latitude]Summarize dataset:  76%|######################################################################9                      | 74/97 [00:11<00:03,  7.60it/s, scatter MedInc, Longitude]Summarize dataset:  77%|#######################################################################9                     | 75/97 [00:11<00:02,  7.65it/s, scatter MedInc, Longitude]Summarize dataset:  77%|######################################################################3                    | 75/97 [00:11<00:02,  7.65it/s, scatter HouseAge, Longitude]Summarize dataset:  78%|#######################################################################2                   | 76/97 [00:11<00:02,  7.47it/s, scatter HouseAge, Longitude]Summarize dataset:  78%|#######################################################################2                   | 76/97 [00:11<00:02,  7.47it/s, scatter AveRooms, Longitude]Summarize dataset:  79%|########################################################################2                  | 77/97 [00:12<00:02,  7.56it/s, scatter AveRooms, Longitude]Summarize dataset:  79%|#######################################################################4                  | 77/97 [00:12<00:02,  7.56it/s, scatter AveBedrms, Longitude]Summarize dataset:  80%|########################################################################3                 | 78/97 [00:12<00:02,  7.31it/s, scatter AveBedrms, Longitude]Summarize dataset:  80%|#######################################################################5                 | 78/97 [00:12<00:02,  7.31it/s, scatter Population, Longitude]Summarize dataset:  81%|########################################################################4                | 79/97 [00:12<00:02,  7.29it/s, scatter Population, Longitude]Summarize dataset:  81%|##########################################################################1                | 79/97 [00:12<00:02,  7.29it/s, scatter AveOccup, Longitude]Summarize dataset:  82%|###########################################################################                | 80/97 [00:12<00:02,  7.32it/s, scatter AveOccup, Longitude]Summarize dataset:  82%|###########################################################################                | 80/97 [00:12<00:02,  7.32it/s, scatter Latitude, Longitude]Summarize dataset:  84%|###########################################################################9               | 81/97 [00:12<00:02,  7.57it/s, scatter Latitude, Longitude]Summarize dataset:  84%|###########################################################################1              | 81/97 [00:12<00:02,  7.57it/s, scatter Longitude, Longitude]Summarize dataset:  85%|############################################################################              | 82/97 [00:12<00:02,  7.48it/s, scatter Longitude, Longitude]Summarize dataset:  85%|##########################################################################3             | 82/97 [00:12<00:02,  7.48it/s, scatter MedHouseVal, Longitude]Summarize dataset:  86%|###########################################################################2            | 83/97 [00:12<00:01,  7.67it/s, scatter MedHouseVal, Longitude]Summarize dataset:  86%|#############################################################################8             | 83/97 [00:12<00:01,  7.67it/s, scatter MedInc, MedHouseVal]Summarize dataset:  87%|##############################################################################8            | 84/97 [00:13<00:01,  7.59it/s, scatter MedInc, MedHouseVal]Summarize dataset:  87%|#############################################################################            | 84/97 [00:13<00:01,  7.59it/s, scatter HouseAge, MedHouseVal]Summarize dataset:  88%|#############################################################################9           | 85/97 [00:13<00:01,  7.40it/s, scatter HouseAge, MedHouseVal]Summarize dataset:  88%|#############################################################################9           | 85/97 [00:13<00:01,  7.40it/s, scatter AveRooms, MedHouseVal]Summarize dataset:  89%|##############################################################################9          | 86/97 [00:13<00:01,  7.62it/s, scatter AveRooms, MedHouseVal]Summarize dataset:  89%|##############################################################################          | 86/97 [00:13<00:01,  7.62it/s, scatter AveBedrms, MedHouseVal]Summarize dataset:  90%|##############################################################################9         | 87/97 [00:13<00:01,  7.35it/s, scatter AveBedrms, MedHouseVal]Summarize dataset:  90%|##############################################################################         | 87/97 [00:13<00:01,  7.35it/s, scatter Population, MedHouseVal]Summarize dataset:  91%|##############################################################################9        | 88/97 [00:13<00:01,  7.34it/s, scatter Population, MedHouseVal]Summarize dataset:  91%|################################################################################7        | 88/97 [00:13<00:01,  7.34it/s, scatter AveOccup, MedHouseVal]Summarize dataset:  92%|#################################################################################6       | 89/97 [00:13<00:01,  7.40it/s, scatter AveOccup, MedHouseVal]Summarize dataset:  92%|#################################################################################6       | 89/97 [00:13<00:01,  7.40it/s, scatter Latitude, MedHouseVal]Summarize dataset:  93%|##################################################################################5      | 90/97 [00:13<00:00,  7.73it/s, scatter Latitude, MedHouseVal]Summarize dataset:  93%|#################################################################################6      | 90/97 [00:13<00:00,  7.73it/s, scatter Longitude, MedHouseVal]Summarize dataset:  94%|##################################################################################5     | 91/97 [00:13<00:00,  7.69it/s, scatter Longitude, MedHouseVal]Summarize dataset:  94%|################################################################################6     | 91/97 [00:13<00:00,  7.69it/s, scatter MedHouseVal, MedHouseVal]Summarize dataset:  95%|#################################################################################5    | 92/97 [00:14<00:00,  7.56it/s, scatter MedHouseVal, MedHouseVal]Summarize dataset:  95%|#########################################################################################1    | 92/97 [00:14<00:00,  7.56it/s, Get dataframe statistics]Summarize dataset:  94%|#############################################################################################      | 93/99 [00:14<00:00,  7.56it/s, Missing diagram bar]Summarize dataset:  95%|##############################################################################################     | 94/99 [00:14<00:00,  7.79it/s, Missing diagram bar]Summarize dataset:  95%|###########################################################################################1    | 94/99 [00:14<00:00,  7.79it/s, Missing diagram matrix]Summarize dataset:  96%|############################################################################################1   | 95/99 [00:14<00:00,  7.98it/s, Missing diagram matrix]Summarize dataset:  96%|######################################################################################################6    | 95/99 [00:14<00:00,  7.98it/s, Take sample]Summarize dataset:  97%|###############################################################################################   | 96/99 [00:14<00:00,  7.98it/s, Detecting duplicates]Summarize dataset:  98%|#########################################################################################################8  | 97/99 [00:14<00:00,  7.98it/s, Get alerts]Summarize dataset:  99%|############################################################################################# | 98/99 [00:14<00:00,  7.98it/s, Get reproduction details]Summarize dataset: 100%|#############################################################################################################| 99/99 [00:14<00:00,  7.98it/s, Completed]Summarize dataset: 100%|#############################################################################################################| 99/99 [00:14<00:00,  6.84it/s, Completed]
2023-01-09 18:09:24,579:WARNING:Generate report structure:   0%|                                                                                                                          | 0/1 [00:00<?, ?it/s]Generate report structure: 100%|##################################################################################################################| 1/1 [00:03<00:00,  3.35s/it]Generate report structure: 100%|##################################################################################################################| 1/1 [00:03<00:00,  3.35s/it]
2023-01-09 18:09:27,594:WARNING:Render HTML:   0%|                                                                                                                                        | 0/1 [00:00<?, ?it/s]Render HTML: 100%|################################################################################################################################| 1/1 [00:03<00:00,  3.02s/it]Render HTML: 100%|################################################################################################################################| 1/1 [00:03<00:00,  3.02s/it]
2023-01-10 10:52:45,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-10 10:52:45,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-10 10:52:45,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-10 10:52:45,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-10 10:52:48,899:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-10 10:52:58,606:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\multimethod\__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

2023-01-10 10:58:45,617:INFO:PyCaret RegressionExperiment
2023-01-10 10:58:45,617:INFO:Logging name: reg-default-name
2023-01-10 10:58:45,617:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-10 10:58:45,617:INFO:version 3.0.0.rc7
2023-01-10 10:58:45,617:INFO:Initializing setup()
2023-01-10 10:58:45,617:INFO:self.USI: ad16
2023-01-10 10:58:45,617:INFO:self._variable_keys: {'logging_param', 'X', 'y_train', 'gpu_param', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'gpu_n_jobs_param', '_available_plots', 'exp_name_log', 'seed', 'memory', 'transform_target_param', 'X_test', 'exp_id', '_ml_usecase', 'fold_groups_param', 'y_test', 'data', 'target_param', 'n_jobs_param', 'idx', 'log_plots_param', 'html_param', 'X_train', 'y', 'USI'}
2023-01-10 10:58:45,617:INFO:Checking environment
2023-01-10 10:58:45,617:INFO:python_version: 3.10.5
2023-01-10 10:58:45,617:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-01-10 10:58:45,617:INFO:machine: AMD64
2023-01-10 10:58:45,637:INFO:platform: Windows-10-10.0.19045-SP0
2023-01-10 10:58:45,642:INFO:Memory: svmem(total=8494747648, available=2588663808, percent=69.5, used=5906083840, free=2588663808)
2023-01-10 10:58:45,642:INFO:Physical Core: 4
2023-01-10 10:58:45,642:INFO:Logical Core: 8
2023-01-10 10:58:45,642:INFO:Checking libraries
2023-01-10 10:58:45,642:INFO:System:
2023-01-10 10:58:45,642:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-01-10 10:58:45,642:INFO:executable: C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\Scripts\python.exe
2023-01-10 10:58:45,643:INFO:   machine: Windows-10-10.0.19045-SP0
2023-01-10 10:58:45,643:INFO:PyCaret required dependencies:
2023-01-10 10:58:45,643:INFO:                 pip: 22.3.1
2023-01-10 10:58:45,643:INFO:          setuptools: 58.1.0
2023-01-10 10:58:45,643:INFO:             pycaret: 3.0.0rc7
2023-01-10 10:58:45,643:INFO:             IPython: 8.8.0
2023-01-10 10:58:45,643:INFO:          ipywidgets: 8.0.4
2023-01-10 10:58:45,643:INFO:                tqdm: 4.64.1
2023-01-10 10:58:45,643:INFO:               numpy: 1.23.5
2023-01-10 10:58:45,643:INFO:              pandas: 1.5.2
2023-01-10 10:58:45,643:INFO:              jinja2: 3.1.2
2023-01-10 10:58:45,643:INFO:               scipy: 1.9.3
2023-01-10 10:58:45,643:INFO:              joblib: 1.2.0
2023-01-10 10:58:45,643:INFO:             sklearn: 1.1.3
2023-01-10 10:58:45,643:INFO:                pyod: 1.0.7
2023-01-10 10:58:45,644:INFO:            imblearn: 0.10.1
2023-01-10 10:58:45,644:INFO:   category_encoders: 2.5.1.post0
2023-01-10 10:58:45,644:INFO:            lightgbm: 3.3.4
2023-01-10 10:58:45,644:INFO:               numba: 0.56.4
2023-01-10 10:58:45,644:INFO:            requests: 2.28.1
2023-01-10 10:58:45,644:INFO:          matplotlib: 3.6.2
2023-01-10 10:58:45,644:INFO:          scikitplot: 0.3.7
2023-01-10 10:58:45,644:INFO:         yellowbrick: 1.5
2023-01-10 10:58:45,644:INFO:              plotly: 5.11.0
2023-01-10 10:58:45,644:INFO:             kaleido: 0.2.1
2023-01-10 10:58:45,644:INFO:         statsmodels: 0.13.5
2023-01-10 10:58:45,644:INFO:              sktime: 0.15.0
2023-01-10 10:58:45,644:INFO:               tbats: 1.1.2
2023-01-10 10:58:45,644:INFO:            pmdarima: 2.0.2
2023-01-10 10:58:45,644:INFO:              psutil: 5.9.4
2023-01-10 10:58:45,644:INFO:PyCaret optional dependencies:
2023-01-10 10:58:45,653:INFO:                shap: Not installed
2023-01-10 10:58:45,653:INFO:           interpret: Not installed
2023-01-10 10:58:45,653:INFO:                umap: Not installed
2023-01-10 10:58:45,653:INFO:    pandas_profiling: 3.6.2
2023-01-10 10:58:45,653:INFO:  explainerdashboard: Not installed
2023-01-10 10:58:45,653:INFO:             autoviz: Not installed
2023-01-10 10:58:45,653:INFO:           fairlearn: Not installed
2023-01-10 10:58:45,653:INFO:             xgboost: Not installed
2023-01-10 10:58:45,653:INFO:            catboost: Not installed
2023-01-10 10:58:45,653:INFO:              kmodes: Not installed
2023-01-10 10:58:45,653:INFO:             mlxtend: Not installed
2023-01-10 10:58:45,653:INFO:       statsforecast: Not installed
2023-01-10 10:58:45,653:INFO:        tune_sklearn: Not installed
2023-01-10 10:58:45,653:INFO:                 ray: Not installed
2023-01-10 10:58:45,653:INFO:            hyperopt: Not installed
2023-01-10 10:58:45,653:INFO:              optuna: Not installed
2023-01-10 10:58:45,653:INFO:               skopt: Not installed
2023-01-10 10:58:45,653:INFO:              mlflow: Not installed
2023-01-10 10:58:45,653:INFO:              gradio: Not installed
2023-01-10 10:58:45,653:INFO:             fastapi: Not installed
2023-01-10 10:58:45,653:INFO:             uvicorn: Not installed
2023-01-10 10:58:45,653:INFO:              m2cgen: Not installed
2023-01-10 10:58:45,653:INFO:           evidently: Not installed
2023-01-10 10:58:45,653:INFO:                nltk: Not installed
2023-01-10 10:58:45,653:INFO:            pyLDAvis: Not installed
2023-01-10 10:58:45,653:INFO:              gensim: Not installed
2023-01-10 10:58:45,653:INFO:               spacy: Not installed
2023-01-10 10:58:45,653:INFO:           wordcloud: Not installed
2023-01-10 10:58:45,653:INFO:            textblob: Not installed
2023-01-10 10:58:45,653:INFO:               fugue: Not installed
2023-01-10 10:58:45,653:INFO:           streamlit: 1.16.0
2023-01-10 10:58:45,653:INFO:             prophet: Not installed
2023-01-10 10:58:45,669:INFO:None
2023-01-10 10:58:45,669:INFO:Set up data.
2023-01-10 10:58:45,676:INFO:Set up train/test split.
2023-01-10 10:58:45,676:INFO:Set up index.
2023-01-10 10:58:45,686:INFO:Set up folding strategy.
2023-01-10 10:58:45,686:INFO:Assigning column types.
2023-01-10 10:58:45,689:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-10 10:58:45,689:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,689:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,702:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:45,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:45,889:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,894:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:45,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,020:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-10 10:58:46,026:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,152:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,267:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-10 10:58:46,283:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,467:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,529:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-10 10:58:46,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,784:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-10 10:58:46,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:46,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:46,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-10 10:58:47,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,042:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-10 10:58:47,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,287:INFO:Preparing preprocessing pipeline...
2023-01-10 10:58:47,287:INFO:Set up simple imputation.
2023-01-10 10:58:47,361:INFO:Finished creating preprocessing pipeline.
2023-01-10 10:58:47,373:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-10 10:58:47,373:INFO:Creating final display dataframe.
2023-01-10 10:58:47,620:INFO:Setup _display_container:                     Description             Value
0                    Session id              8203
1                        Target       MedHouseVal
2                   Target type        Regression
3           Original data shape        (15480, 9)
4        Transformed data shape        (15480, 9)
5   Transformed train set shape        (10836, 9)
6    Transformed test set shape         (4644, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ad16
2023-01-10 10:58:47,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-10 10:58:47,883:INFO:setup() successfully completed in 2.28s...............
2023-01-10 10:58:47,954:INFO:Initializing compare_models()
2023-01-10 10:58:47,954:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-10 10:58:47,955:INFO:Checking exceptions
2023-01-10 10:58:47,958:INFO:Preparing display monitor
2023-01-10 10:58:47,963:INFO:Initializing Linear Regression
2023-01-10 10:58:47,963:INFO:Total runtime is 0.0 minutes
2023-01-10 10:58:47,963:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:47,964:INFO:Initializing create_model()
2023-01-10 10:58:47,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:47,964:INFO:Checking exceptions
2023-01-10 10:58:47,964:INFO:Importing libraries
2023-01-10 10:58:47,964:INFO:Copying training dataset
2023-01-10 10:58:47,968:INFO:Defining folds
2023-01-10 10:58:47,968:INFO:Declaring metric variables
2023-01-10 10:58:47,968:INFO:Importing untrained model
2023-01-10 10:58:47,968:INFO:Linear Regression Imported successfully
2023-01-10 10:58:47,969:INFO:Starting cross validation
2023-01-10 10:58:47,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:52,501:INFO:Calculating mean and std
2023-01-10 10:58:52,502:INFO:Creating metrics dataframe
2023-01-10 10:58:52,506:INFO:Uploading results into container
2023-01-10 10:58:52,507:INFO:Uploading model into container now
2023-01-10 10:58:52,507:INFO:_master_model_container: 1
2023-01-10 10:58:52,508:INFO:_display_container: 2
2023-01-10 10:58:52,508:INFO:LinearRegression(n_jobs=-1)
2023-01-10 10:58:52,508:INFO:create_model() successfully completed......................................
2023-01-10 10:58:52,603:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:52,603:INFO:Creating metrics dataframe
2023-01-10 10:58:52,608:INFO:Initializing Lasso Regression
2023-01-10 10:58:52,608:INFO:Total runtime is 0.0774297038714091 minutes
2023-01-10 10:58:52,608:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:52,608:INFO:Initializing create_model()
2023-01-10 10:58:52,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:52,608:INFO:Checking exceptions
2023-01-10 10:58:52,608:INFO:Importing libraries
2023-01-10 10:58:52,609:INFO:Copying training dataset
2023-01-10 10:58:52,612:INFO:Defining folds
2023-01-10 10:58:52,613:INFO:Declaring metric variables
2023-01-10 10:58:52,613:INFO:Importing untrained model
2023-01-10 10:58:52,614:INFO:Lasso Regression Imported successfully
2023-01-10 10:58:52,614:INFO:Starting cross validation
2023-01-10 10:58:52,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:52,760:INFO:Calculating mean and std
2023-01-10 10:58:52,761:INFO:Creating metrics dataframe
2023-01-10 10:58:52,765:INFO:Uploading results into container
2023-01-10 10:58:52,765:INFO:Uploading model into container now
2023-01-10 10:58:52,766:INFO:_master_model_container: 2
2023-01-10 10:58:52,766:INFO:_display_container: 2
2023-01-10 10:58:52,766:INFO:Lasso(random_state=8203)
2023-01-10 10:58:52,766:INFO:create_model() successfully completed......................................
2023-01-10 10:58:52,862:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:52,862:INFO:Creating metrics dataframe
2023-01-10 10:58:52,867:INFO:Initializing Ridge Regression
2023-01-10 10:58:52,867:INFO:Total runtime is 0.08174167474110922 minutes
2023-01-10 10:58:52,868:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:52,868:INFO:Initializing create_model()
2023-01-10 10:58:52,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:52,868:INFO:Checking exceptions
2023-01-10 10:58:52,868:INFO:Importing libraries
2023-01-10 10:58:52,868:INFO:Copying training dataset
2023-01-10 10:58:52,873:INFO:Defining folds
2023-01-10 10:58:52,873:INFO:Declaring metric variables
2023-01-10 10:58:52,873:INFO:Importing untrained model
2023-01-10 10:58:52,874:INFO:Ridge Regression Imported successfully
2023-01-10 10:58:52,874:INFO:Starting cross validation
2023-01-10 10:58:52,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:52,934:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.46821e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,935:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.62701e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,935:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.58591e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,947:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.74244e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,958:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.60347e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,965:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.56234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,974:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.61617e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,991:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.62917e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:52,991:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.62984e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:53,005:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=1.64234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-01-10 10:58:53,025:INFO:Calculating mean and std
2023-01-10 10:58:53,026:INFO:Creating metrics dataframe
2023-01-10 10:58:53,030:INFO:Uploading results into container
2023-01-10 10:58:53,031:INFO:Uploading model into container now
2023-01-10 10:58:53,031:INFO:_master_model_container: 3
2023-01-10 10:58:53,031:INFO:_display_container: 2
2023-01-10 10:58:53,032:INFO:Ridge(random_state=8203)
2023-01-10 10:58:53,032:INFO:create_model() successfully completed......................................
2023-01-10 10:58:53,127:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:53,127:INFO:Creating metrics dataframe
2023-01-10 10:58:53,133:INFO:Initializing Elastic Net
2023-01-10 10:58:53,133:INFO:Total runtime is 0.08617260456085206 minutes
2023-01-10 10:58:53,133:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:53,134:INFO:Initializing create_model()
2023-01-10 10:58:53,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:53,134:INFO:Checking exceptions
2023-01-10 10:58:53,134:INFO:Importing libraries
2023-01-10 10:58:53,134:INFO:Copying training dataset
2023-01-10 10:58:53,138:INFO:Defining folds
2023-01-10 10:58:53,138:INFO:Declaring metric variables
2023-01-10 10:58:53,138:INFO:Importing untrained model
2023-01-10 10:58:53,139:INFO:Elastic Net Imported successfully
2023-01-10 10:58:53,139:INFO:Starting cross validation
2023-01-10 10:58:53,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:53,275:INFO:Calculating mean and std
2023-01-10 10:58:53,276:INFO:Creating metrics dataframe
2023-01-10 10:58:53,279:INFO:Uploading results into container
2023-01-10 10:58:53,280:INFO:Uploading model into container now
2023-01-10 10:58:53,281:INFO:_master_model_container: 4
2023-01-10 10:58:53,281:INFO:_display_container: 2
2023-01-10 10:58:53,281:INFO:ElasticNet(random_state=8203)
2023-01-10 10:58:53,281:INFO:create_model() successfully completed......................................
2023-01-10 10:58:53,374:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:53,374:INFO:Creating metrics dataframe
2023-01-10 10:58:53,379:INFO:Initializing Least Angle Regression
2023-01-10 10:58:53,380:INFO:Total runtime is 0.09028916358947754 minutes
2023-01-10 10:58:53,380:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:53,380:INFO:Initializing create_model()
2023-01-10 10:58:53,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:53,380:INFO:Checking exceptions
2023-01-10 10:58:53,380:INFO:Importing libraries
2023-01-10 10:58:53,380:INFO:Copying training dataset
2023-01-10 10:58:53,384:INFO:Defining folds
2023-01-10 10:58:53,384:INFO:Declaring metric variables
2023-01-10 10:58:53,385:INFO:Importing untrained model
2023-01-10 10:58:53,385:INFO:Least Angle Regression Imported successfully
2023-01-10 10:58:53,385:INFO:Starting cross validation
2023-01-10 10:58:53,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:53,433:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,440:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,452:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,463:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,466:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,481:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,493:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,501:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,512:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,522:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,534:INFO:Calculating mean and std
2023-01-10 10:58:53,535:INFO:Creating metrics dataframe
2023-01-10 10:58:53,538:INFO:Uploading results into container
2023-01-10 10:58:53,539:INFO:Uploading model into container now
2023-01-10 10:58:53,540:INFO:_master_model_container: 5
2023-01-10 10:58:53,540:INFO:_display_container: 2
2023-01-10 10:58:53,540:INFO:Lars(random_state=8203)
2023-01-10 10:58:53,540:INFO:create_model() successfully completed......................................
2023-01-10 10:58:53,634:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:53,634:INFO:Creating metrics dataframe
2023-01-10 10:58:53,639:INFO:Initializing Lasso Least Angle Regression
2023-01-10 10:58:53,639:INFO:Total runtime is 0.09460755586624146 minutes
2023-01-10 10:58:53,639:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:53,640:INFO:Initializing create_model()
2023-01-10 10:58:53,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:53,640:INFO:Checking exceptions
2023-01-10 10:58:53,640:INFO:Importing libraries
2023-01-10 10:58:53,640:INFO:Copying training dataset
2023-01-10 10:58:53,644:INFO:Defining folds
2023-01-10 10:58:53,645:INFO:Declaring metric variables
2023-01-10 10:58:53,645:INFO:Importing untrained model
2023-01-10 10:58:53,646:INFO:Lasso Least Angle Regression Imported successfully
2023-01-10 10:58:53,646:INFO:Starting cross validation
2023-01-10 10:58:53,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:53,689:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,697:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,707:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,721:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,731:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,735:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,747:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,757:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,757:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,772:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-10 10:58:53,782:INFO:Calculating mean and std
2023-01-10 10:58:53,783:INFO:Creating metrics dataframe
2023-01-10 10:58:53,787:INFO:Uploading results into container
2023-01-10 10:58:53,789:INFO:Uploading model into container now
2023-01-10 10:58:53,789:INFO:_master_model_container: 6
2023-01-10 10:58:53,790:INFO:_display_container: 2
2023-01-10 10:58:53,790:INFO:LassoLars(random_state=8203)
2023-01-10 10:58:53,790:INFO:create_model() successfully completed......................................
2023-01-10 10:58:53,876:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:53,876:INFO:Creating metrics dataframe
2023-01-10 10:58:53,891:INFO:Initializing Orthogonal Matching Pursuit
2023-01-10 10:58:53,891:INFO:Total runtime is 0.09880267381668091 minutes
2023-01-10 10:58:53,891:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:53,891:INFO:Initializing create_model()
2023-01-10 10:58:53,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:53,891:INFO:Checking exceptions
2023-01-10 10:58:53,892:INFO:Importing libraries
2023-01-10 10:58:53,892:INFO:Copying training dataset
2023-01-10 10:58:53,896:INFO:Defining folds
2023-01-10 10:58:53,896:INFO:Declaring metric variables
2023-01-10 10:58:53,896:INFO:Importing untrained model
2023-01-10 10:58:53,896:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-10 10:58:53,897:INFO:Starting cross validation
2023-01-10 10:58:53,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:53,939:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,949:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,957:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,957:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,980:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:53,991:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:54,005:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:54,011:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:54,018:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:54,029:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-10 10:58:54,042:INFO:Calculating mean and std
2023-01-10 10:58:54,043:INFO:Creating metrics dataframe
2023-01-10 10:58:54,046:INFO:Uploading results into container
2023-01-10 10:58:54,047:INFO:Uploading model into container now
2023-01-10 10:58:54,047:INFO:_master_model_container: 7
2023-01-10 10:58:54,047:INFO:_display_container: 2
2023-01-10 10:58:54,048:INFO:OrthogonalMatchingPursuit()
2023-01-10 10:58:54,048:INFO:create_model() successfully completed......................................
2023-01-10 10:58:54,143:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:54,143:INFO:Creating metrics dataframe
2023-01-10 10:58:54,148:INFO:Initializing Bayesian Ridge
2023-01-10 10:58:54,149:INFO:Total runtime is 0.10310927232106527 minutes
2023-01-10 10:58:54,149:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:54,149:INFO:Initializing create_model()
2023-01-10 10:58:54,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:54,149:INFO:Checking exceptions
2023-01-10 10:58:54,149:INFO:Importing libraries
2023-01-10 10:58:54,149:INFO:Copying training dataset
2023-01-10 10:58:54,153:INFO:Defining folds
2023-01-10 10:58:54,153:INFO:Declaring metric variables
2023-01-10 10:58:54,154:INFO:Importing untrained model
2023-01-10 10:58:54,155:INFO:Bayesian Ridge Imported successfully
2023-01-10 10:58:54,155:INFO:Starting cross validation
2023-01-10 10:58:54,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:54,285:INFO:Calculating mean and std
2023-01-10 10:58:54,285:INFO:Creating metrics dataframe
2023-01-10 10:58:54,295:INFO:Uploading results into container
2023-01-10 10:58:54,296:INFO:Uploading model into container now
2023-01-10 10:58:54,296:INFO:_master_model_container: 8
2023-01-10 10:58:54,296:INFO:_display_container: 2
2023-01-10 10:58:54,297:INFO:BayesianRidge()
2023-01-10 10:58:54,297:INFO:create_model() successfully completed......................................
2023-01-10 10:58:54,388:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:54,388:INFO:Creating metrics dataframe
2023-01-10 10:58:54,393:INFO:Initializing Passive Aggressive Regressor
2023-01-10 10:58:54,394:INFO:Total runtime is 0.10718841950098675 minutes
2023-01-10 10:58:54,394:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:54,394:INFO:Initializing create_model()
2023-01-10 10:58:54,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:54,394:INFO:Checking exceptions
2023-01-10 10:58:54,394:INFO:Importing libraries
2023-01-10 10:58:54,394:INFO:Copying training dataset
2023-01-10 10:58:54,398:INFO:Defining folds
2023-01-10 10:58:54,398:INFO:Declaring metric variables
2023-01-10 10:58:54,398:INFO:Importing untrained model
2023-01-10 10:58:54,399:INFO:Passive Aggressive Regressor Imported successfully
2023-01-10 10:58:54,399:INFO:Starting cross validation
2023-01-10 10:58:54,400:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:54,573:INFO:Calculating mean and std
2023-01-10 10:58:54,573:INFO:Creating metrics dataframe
2023-01-10 10:58:54,577:INFO:Uploading results into container
2023-01-10 10:58:54,578:INFO:Uploading model into container now
2023-01-10 10:58:54,578:INFO:_master_model_container: 9
2023-01-10 10:58:54,578:INFO:_display_container: 2
2023-01-10 10:58:54,579:INFO:PassiveAggressiveRegressor(random_state=8203)
2023-01-10 10:58:54,579:INFO:create_model() successfully completed......................................
2023-01-10 10:58:54,673:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:54,673:INFO:Creating metrics dataframe
2023-01-10 10:58:54,688:INFO:Initializing Huber Regressor
2023-01-10 10:58:54,688:INFO:Total runtime is 0.11208932002385458 minutes
2023-01-10 10:58:54,689:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:54,689:INFO:Initializing create_model()
2023-01-10 10:58:54,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:54,689:INFO:Checking exceptions
2023-01-10 10:58:54,689:INFO:Importing libraries
2023-01-10 10:58:54,689:INFO:Copying training dataset
2023-01-10 10:58:54,689:INFO:Defining folds
2023-01-10 10:58:54,689:INFO:Declaring metric variables
2023-01-10 10:58:54,689:INFO:Importing untrained model
2023-01-10 10:58:54,689:INFO:Huber Regressor Imported successfully
2023-01-10 10:58:54,697:INFO:Starting cross validation
2023-01-10 10:58:54,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:55,419:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,420:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,507:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,524:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,541:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,591:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,619:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,639:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,721:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,722:WARNING:C:\Users\alepi\Documents\projects\personal\repos\streamlit_app\env\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-10 10:58:55,732:INFO:Calculating mean and std
2023-01-10 10:58:55,733:INFO:Creating metrics dataframe
2023-01-10 10:58:55,738:INFO:Uploading results into container
2023-01-10 10:58:55,741:INFO:Uploading model into container now
2023-01-10 10:58:55,742:INFO:_master_model_container: 10
2023-01-10 10:58:55,742:INFO:_display_container: 2
2023-01-10 10:58:55,742:INFO:HuberRegressor()
2023-01-10 10:58:55,742:INFO:create_model() successfully completed......................................
2023-01-10 10:58:55,835:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:55,835:INFO:Creating metrics dataframe
2023-01-10 10:58:55,840:INFO:Initializing K Neighbors Regressor
2023-01-10 10:58:55,841:INFO:Total runtime is 0.1313055197397868 minutes
2023-01-10 10:58:55,841:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:55,841:INFO:Initializing create_model()
2023-01-10 10:58:55,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:55,841:INFO:Checking exceptions
2023-01-10 10:58:55,841:INFO:Importing libraries
2023-01-10 10:58:55,841:INFO:Copying training dataset
2023-01-10 10:58:55,845:INFO:Defining folds
2023-01-10 10:58:55,845:INFO:Declaring metric variables
2023-01-10 10:58:55,846:INFO:Importing untrained model
2023-01-10 10:58:55,846:INFO:K Neighbors Regressor Imported successfully
2023-01-10 10:58:55,846:INFO:Starting cross validation
2023-01-10 10:58:55,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:56,040:INFO:Calculating mean and std
2023-01-10 10:58:56,040:INFO:Creating metrics dataframe
2023-01-10 10:58:56,047:INFO:Uploading results into container
2023-01-10 10:58:56,049:INFO:Uploading model into container now
2023-01-10 10:58:56,049:INFO:_master_model_container: 11
2023-01-10 10:58:56,049:INFO:_display_container: 2
2023-01-10 10:58:56,049:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-10 10:58:56,049:INFO:create_model() successfully completed......................................
2023-01-10 10:58:56,156:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:56,156:INFO:Creating metrics dataframe
2023-01-10 10:58:56,156:INFO:Initializing Decision Tree Regressor
2023-01-10 10:58:56,156:INFO:Total runtime is 0.1365543047587077 minutes
2023-01-10 10:58:56,156:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:56,156:INFO:Initializing create_model()
2023-01-10 10:58:56,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:56,156:INFO:Checking exceptions
2023-01-10 10:58:56,156:INFO:Importing libraries
2023-01-10 10:58:56,156:INFO:Copying training dataset
2023-01-10 10:58:56,156:INFO:Defining folds
2023-01-10 10:58:56,156:INFO:Declaring metric variables
2023-01-10 10:58:56,156:INFO:Importing untrained model
2023-01-10 10:58:56,156:INFO:Decision Tree Regressor Imported successfully
2023-01-10 10:58:56,169:INFO:Starting cross validation
2023-01-10 10:58:56,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:58:56,540:INFO:Calculating mean and std
2023-01-10 10:58:56,540:INFO:Creating metrics dataframe
2023-01-10 10:58:56,551:INFO:Uploading results into container
2023-01-10 10:58:56,552:INFO:Uploading model into container now
2023-01-10 10:58:56,552:INFO:_master_model_container: 12
2023-01-10 10:58:56,552:INFO:_display_container: 2
2023-01-10 10:58:56,553:INFO:DecisionTreeRegressor(random_state=8203)
2023-01-10 10:58:56,553:INFO:create_model() successfully completed......................................
2023-01-10 10:58:56,655:INFO:SubProcess create_model() end ==================================
2023-01-10 10:58:56,655:INFO:Creating metrics dataframe
2023-01-10 10:58:56,661:INFO:Initializing Random Forest Regressor
2023-01-10 10:58:56,661:INFO:Total runtime is 0.14496595064798992 minutes
2023-01-10 10:58:56,661:INFO:SubProcess create_model() called ==================================
2023-01-10 10:58:56,661:INFO:Initializing create_model()
2023-01-10 10:58:56,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:58:56,661:INFO:Checking exceptions
2023-01-10 10:58:56,661:INFO:Importing libraries
2023-01-10 10:58:56,661:INFO:Copying training dataset
2023-01-10 10:58:56,665:INFO:Defining folds
2023-01-10 10:58:56,665:INFO:Declaring metric variables
2023-01-10 10:58:56,666:INFO:Importing untrained model
2023-01-10 10:58:56,666:INFO:Random Forest Regressor Imported successfully
2023-01-10 10:58:56,667:INFO:Starting cross validation
2023-01-10 10:58:56,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:09,394:INFO:Calculating mean and std
2023-01-10 10:59:09,395:INFO:Creating metrics dataframe
2023-01-10 10:59:09,402:INFO:Uploading results into container
2023-01-10 10:59:09,403:INFO:Uploading model into container now
2023-01-10 10:59:09,405:INFO:_master_model_container: 13
2023-01-10 10:59:09,406:INFO:_display_container: 2
2023-01-10 10:59:09,406:INFO:RandomForestRegressor(n_jobs=-1, random_state=8203)
2023-01-10 10:59:09,406:INFO:create_model() successfully completed......................................
2023-01-10 10:59:09,530:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:09,530:INFO:Creating metrics dataframe
2023-01-10 10:59:09,537:INFO:Initializing Extra Trees Regressor
2023-01-10 10:59:09,537:INFO:Total runtime is 0.359572168191274 minutes
2023-01-10 10:59:09,538:INFO:SubProcess create_model() called ==================================
2023-01-10 10:59:09,538:INFO:Initializing create_model()
2023-01-10 10:59:09,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:09,538:INFO:Checking exceptions
2023-01-10 10:59:09,538:INFO:Importing libraries
2023-01-10 10:59:09,538:INFO:Copying training dataset
2023-01-10 10:59:09,543:INFO:Defining folds
2023-01-10 10:59:09,543:INFO:Declaring metric variables
2023-01-10 10:59:09,544:INFO:Importing untrained model
2023-01-10 10:59:09,544:INFO:Extra Trees Regressor Imported successfully
2023-01-10 10:59:09,545:INFO:Starting cross validation
2023-01-10 10:59:09,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:17,283:INFO:Calculating mean and std
2023-01-10 10:59:17,283:INFO:Creating metrics dataframe
2023-01-10 10:59:17,295:INFO:Uploading results into container
2023-01-10 10:59:17,298:INFO:Uploading model into container now
2023-01-10 10:59:17,299:INFO:_master_model_container: 14
2023-01-10 10:59:17,299:INFO:_display_container: 2
2023-01-10 10:59:17,300:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8203)
2023-01-10 10:59:17,300:INFO:create_model() successfully completed......................................
2023-01-10 10:59:17,428:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:17,428:INFO:Creating metrics dataframe
2023-01-10 10:59:17,428:INFO:Initializing AdaBoost Regressor
2023-01-10 10:59:17,428:INFO:Total runtime is 0.49109540780385336 minutes
2023-01-10 10:59:17,428:INFO:SubProcess create_model() called ==================================
2023-01-10 10:59:17,428:INFO:Initializing create_model()
2023-01-10 10:59:17,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:17,428:INFO:Checking exceptions
2023-01-10 10:59:17,428:INFO:Importing libraries
2023-01-10 10:59:17,428:INFO:Copying training dataset
2023-01-10 10:59:17,428:INFO:Defining folds
2023-01-10 10:59:17,444:INFO:Declaring metric variables
2023-01-10 10:59:17,444:INFO:Importing untrained model
2023-01-10 10:59:17,444:INFO:AdaBoost Regressor Imported successfully
2023-01-10 10:59:17,445:INFO:Starting cross validation
2023-01-10 10:59:17,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:19,043:INFO:Calculating mean and std
2023-01-10 10:59:19,043:INFO:Creating metrics dataframe
2023-01-10 10:59:19,055:INFO:Uploading results into container
2023-01-10 10:59:19,056:INFO:Uploading model into container now
2023-01-10 10:59:19,056:INFO:_master_model_container: 15
2023-01-10 10:59:19,057:INFO:_display_container: 2
2023-01-10 10:59:19,057:INFO:AdaBoostRegressor(random_state=8203)
2023-01-10 10:59:19,057:INFO:create_model() successfully completed......................................
2023-01-10 10:59:19,145:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:19,145:INFO:Creating metrics dataframe
2023-01-10 10:59:19,145:INFO:Initializing Gradient Boosting Regressor
2023-01-10 10:59:19,145:INFO:Total runtime is 0.519701886177063 minutes
2023-01-10 10:59:19,145:INFO:SubProcess create_model() called ==================================
2023-01-10 10:59:19,145:INFO:Initializing create_model()
2023-01-10 10:59:19,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:19,145:INFO:Checking exceptions
2023-01-10 10:59:19,145:INFO:Importing libraries
2023-01-10 10:59:19,145:INFO:Copying training dataset
2023-01-10 10:59:19,145:INFO:Defining folds
2023-01-10 10:59:19,145:INFO:Declaring metric variables
2023-01-10 10:59:19,145:INFO:Importing untrained model
2023-01-10 10:59:19,160:INFO:Gradient Boosting Regressor Imported successfully
2023-01-10 10:59:19,161:INFO:Starting cross validation
2023-01-10 10:59:19,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:24,661:INFO:Calculating mean and std
2023-01-10 10:59:24,661:INFO:Creating metrics dataframe
2023-01-10 10:59:24,668:INFO:Uploading results into container
2023-01-10 10:59:24,669:INFO:Uploading model into container now
2023-01-10 10:59:24,670:INFO:_master_model_container: 16
2023-01-10 10:59:24,670:INFO:_display_container: 2
2023-01-10 10:59:24,670:INFO:GradientBoostingRegressor(random_state=8203)
2023-01-10 10:59:24,670:INFO:create_model() successfully completed......................................
2023-01-10 10:59:24,746:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:24,746:INFO:Creating metrics dataframe
2023-01-10 10:59:24,761:INFO:Initializing Light Gradient Boosting Machine
2023-01-10 10:59:24,761:INFO:Total runtime is 0.6133125543594361 minutes
2023-01-10 10:59:24,761:INFO:SubProcess create_model() called ==================================
2023-01-10 10:59:24,761:INFO:Initializing create_model()
2023-01-10 10:59:24,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:24,761:INFO:Checking exceptions
2023-01-10 10:59:24,761:INFO:Importing libraries
2023-01-10 10:59:24,761:INFO:Copying training dataset
2023-01-10 10:59:24,761:INFO:Defining folds
2023-01-10 10:59:24,761:INFO:Declaring metric variables
2023-01-10 10:59:24,761:INFO:Importing untrained model
2023-01-10 10:59:24,761:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-10 10:59:24,772:INFO:Starting cross validation
2023-01-10 10:59:24,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:25,411:INFO:Calculating mean and std
2023-01-10 10:59:25,413:INFO:Creating metrics dataframe
2023-01-10 10:59:25,417:INFO:Uploading results into container
2023-01-10 10:59:25,418:INFO:Uploading model into container now
2023-01-10 10:59:25,419:INFO:_master_model_container: 17
2023-01-10 10:59:25,419:INFO:_display_container: 2
2023-01-10 10:59:25,420:INFO:LGBMRegressor(random_state=8203)
2023-01-10 10:59:25,420:INFO:create_model() successfully completed......................................
2023-01-10 10:59:25,513:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:25,513:INFO:Creating metrics dataframe
2023-01-10 10:59:25,513:INFO:Initializing Dummy Regressor
2023-01-10 10:59:25,513:INFO:Total runtime is 0.6258370637893678 minutes
2023-01-10 10:59:25,513:INFO:SubProcess create_model() called ==================================
2023-01-10 10:59:25,513:INFO:Initializing create_model()
2023-01-10 10:59:25,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224F024AE90>, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:25,513:INFO:Checking exceptions
2023-01-10 10:59:25,513:INFO:Importing libraries
2023-01-10 10:59:25,513:INFO:Copying training dataset
2023-01-10 10:59:25,513:INFO:Defining folds
2023-01-10 10:59:25,513:INFO:Declaring metric variables
2023-01-10 10:59:25,513:INFO:Importing untrained model
2023-01-10 10:59:25,513:INFO:Dummy Regressor Imported successfully
2023-01-10 10:59:25,513:INFO:Starting cross validation
2023-01-10 10:59:25,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-01-10 10:59:25,664:INFO:Calculating mean and std
2023-01-10 10:59:25,664:INFO:Creating metrics dataframe
2023-01-10 10:59:25,675:INFO:Uploading results into container
2023-01-10 10:59:25,676:INFO:Uploading model into container now
2023-01-10 10:59:25,676:INFO:_master_model_container: 18
2023-01-10 10:59:25,677:INFO:_display_container: 2
2023-01-10 10:59:25,677:INFO:DummyRegressor()
2023-01-10 10:59:25,677:INFO:create_model() successfully completed......................................
2023-01-10 10:59:25,762:INFO:SubProcess create_model() end ==================================
2023-01-10 10:59:25,762:INFO:Creating metrics dataframe
2023-01-10 10:59:25,777:INFO:Initializing create_model()
2023-01-10 10:59:25,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000224EFE0FEB0>, estimator=LGBMRegressor(random_state=8203), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-10 10:59:25,778:INFO:Checking exceptions
2023-01-10 10:59:25,778:INFO:Importing libraries
2023-01-10 10:59:25,778:INFO:Copying training dataset
2023-01-10 10:59:25,783:INFO:Defining folds
2023-01-10 10:59:25,784:INFO:Declaring metric variables
2023-01-10 10:59:25,784:INFO:Importing untrained model
2023-01-10 10:59:25,784:INFO:Declaring custom model
2023-01-10 10:59:25,785:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-10 10:59:25,786:INFO:Cross validation set to False
2023-01-10 10:59:25,786:INFO:Fitting Model
2023-01-10 10:59:25,915:INFO:LGBMRegressor(random_state=8203)
2023-01-10 10:59:25,915:INFO:create_model() successfully completed......................................
2023-01-10 10:59:26,091:INFO:_master_model_container: 18
2023-01-10 10:59:26,091:INFO:_display_container: 2
2023-01-10 10:59:26,092:INFO:LGBMRegressor(random_state=8203)
2023-01-10 10:59:26,092:INFO:compare_models() successfully completed......................................
2023-01-10 10:59:26,100:INFO:Initializing save_model()
2023-01-10 10:59:26,100:INFO:save_model(model=LGBMRegressor(random_state=8203), model_name=best_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-10 10:59:26,100:INFO:Adding model into prep_pipe
2023-01-10 10:59:26,119:INFO:best_model.pkl saved in current working directory
2023-01-10 10:59:26,130:INFO:Pipeline(memory=Memory(location=C:\Users\alepi\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MedInc', 'HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', LGBMRegressor(random_state=8203))])
2023-01-10 10:59:26,130:INFO:save_model() successfully completed......................................
